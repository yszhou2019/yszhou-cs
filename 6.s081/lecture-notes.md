

## lab util



```
ä»leftå¬
	å¦‚æœå…³é—­äº†ï¼Œé‚£ä¹ˆå°±close(right[1]),å¬right[0]ï¼Œç­‰å¾…right[0]å…³é—­ï¼Œæœ€åclose(left[0])å’Œleft[1]
```

isolation





Monolithic kernel design

å†…æ ¸åŒ…æ‹¬vm process ... 

good: improve performance, share cache bewteen subsys

bad: itergration



micro kernel designs

bad: user mode and kernel mode switch frequentyly







## **lab syscall**

Trace:

key point
1 add new filed in proc struct
2 specify between num and 1<<num



Sysinfotest key points:
use `freemem()` to get the amount of free memory, do not forget to recover` kmem.freelist` to init state



## **lecture 4**

page tables(vm)



Map stores in memory, and MMU just looks into the map and translate va to pa.

Each process has its own maps, stored in satp register.

MMU exists in hw, not in OS



Three tree level page tables
can allocate page table on demand, not allocating all entries in the beginning





`proc.c` 

`kalloc.c` things about physical memory allocate and free inside kernel

`vm.c` things about vm( pagetable, PTEs and mappings ) and pa



user state addr: which is va, need to walk down the pagetable, then tranlated into pa
kernel state addr: just the pa, do not need to be translated



`uvmcreate()` allocate a new pagetable
`mappages()`  find PTEs and set mapping relations between va and pa
`uvmalloc()`  allocate mem; find PTEs and set mappings (series revokes of mappages)
`uvmunmap()` unset PTEs; (optional) free mem
`uvmdealloc()` series revoke of umap

`copyout()` copy from kernel (pa) to user(va, need to be mapped)
`copyin()` copy from user(va, need to be mapped) to kernel(pa)

`kvmmake()` set direct-map for kernel pagetable
`kvmmap()` wrapper of `mappages()`

`kvminitart()` switch h/w pagetable register to kernel's pagetable





## **lab page tables**

### speed up syscall usyscall



key points:

allocate and init new page in `allocporc()`
free this page in `freepage()`
use `mappages()` to register this page in page table
this page's permission bits should be only-read and user-access 

USYSCALL, a va -> one new page
at the start, stores `struct usyscall` 

allocate a new page(not page table), memcpy pid, add it to pagetable, and set bitwise PTE_E | PTE_R. Don't forget to free PTE from pagetable.



quiz





### print pgtlb

only print pagetable for process(whose pid is 1)

quiz



### detect which pages have been accessed

`pgaccess(va, pg_num, abits)`

PTE_A, ref`riscv-privileged-20190608.pdf page68`



key points

get 3 args, using `argaddr`, `argint`
use `walk` to check vm -> pte, check `PTE_A` bit
after checking `PTE_A` bit, need to unset this bit



Hints:

Don't forget to add walk() prototype in `defs.h`, otherwise will case compilation failed



## lab traps

how syscalls are implemented using traps

### risc-v assembly



### backtrace

Your `backtrace` should use these frame pointers to walk up the stack and **print the saved return address** in each stack frame.



ä¸ºä»€ä¹ˆè¦æ‰“å°return_addr?

> backtraceå°±æ˜¯å‘ç”Ÿerrorçš„æ—¶å€™ï¼Œä¸€å±‚å±‚çš„å‡½æ•°è°ƒç”¨ï¼Œå› æ­¤æ‰“å°return address



![I-riscv-slides](./images/I-riscv-slides.png)



### alarm

add feature `alarm`



test0
ç”¨æˆ·è¿›ç¨‹åœ¨kernel stateçŠ¶æ€ï¼Œå¦‚ä½•è§¦å‘handler()?é—®é¢˜çš„å…³é”®æ˜¯ï¼Œè¿›ç¨‹å½“å‰å¤„äºå†…æ ¸æ€ï¼Œå¦‚ä½•æ‰§è¡Œç”¨æˆ·æ€çš„handlerï¼Ÿ

> éœ€è¦æŠŠpagetableåˆ‡æ¢åˆ°userçš„pagetableï¼Œæ‰èƒ½æ­£å¸¸æ‰§è¡Œhandler()ï¼Œæ‰§è¡Œå®Œä¹‹åè¿˜éœ€è¦è¿”å›ã€‚ä¹Ÿå°±æ˜¯ï¼Œhandlerçš„paå­˜åœ¨äºuser page tableï¼Œåªè¦èƒ½å¤Ÿè·å–user pagetableï¼Œé‚£ä¹ˆå°±å¯ä»¥å¾—åˆ°handlerçš„paï¼Œä»è€Œåœ¨kernel stateç›´æ¥æ‰§è¡Œpaï¼ˆæ€è·¯é”™è¯¯ï¼Œ**ä¸ºä»€ä¹ˆé”™è¯¯?kernel stateä¸æ‰§è¡Œä»»ä½•user codeï¼Œåªæœ‰user stateæ‰ä¼šæ­£å¸¸æ‰§è¡Œuser code**ï¼‰
>
> æ­£ç¡®çš„æ€è·¯ï¼šepcä¿å­˜çš„æ˜¯ä¹‹å‰user stackçš„pcï¼Œç›´æ¥æŠŠepcè®¾ç½®ä¸ºhandlerçš„åœ°å€ï¼Œè¿™æ ·å­ï¼Œæ—¶é’Ÿä¸­æ–­ç»“æŸåå°±ä¼šè¿”å›user stackç›´æ¥æ‰§è¡Œhandlerï¼›å¹¶ä¸”handlerä¼šè°ƒç”¨sigreturnï¼Œåœ¨è¿™ä¸ªsyscallé‡Œé¢é‡æ–°æ¢å¤epcï¼Œå°±å¯ä»¥ä¿è¯å½“å‰processå†æ¬¡è¿è¡Œçš„æ—¶å€™ï¼Œæ­£å¸¸æ‰§è¡Œä¹‹å‰çš„codeï¼ˆä¹Ÿå°±æ˜¯è¯´ï¼Œå€ŸåŠ©æ—¶é’Ÿinterruptï¼Œå½“å‰processæ»¡è¶³ticks=intervalï¼Œä¸‹æ¬¡è¿è¡Œæ—¶ï¼Œpcç›´æ¥è®¾ç½®ä¸ºhandlerï¼Œæ‰§è¡Œå®Œæ¯•ä¼šè°ƒç”¨sigreturnï¼Œæ¢å¤åˆ°epcï¼‰
>
> **Kernel åªæ‰§è¡Œkernelçš„functions, dataï¼Œæœ€å¤šå¯ä»¥é€šè¿‡pagetableè®¿é—®user pageçš„data(proc.pagetableä¿å­˜çš„æ˜¯user page table)ï¼Œä½†æ˜¯ä¸å…·å¤‡æ‰§è¡Œuser codeçš„èƒ½åŠ›**



Test1ï¼Œè¦æ±‚user processåœ¨time interruptä¹‹åï¼Œèƒ½å¤Ÿæ­£ç¡®æ‰§è¡Œä¹‹å‰çš„å‘½ä»¤

Test2ï¼Œè¦æ±‚user processçš„handlerä¸å¯é‡å…¥(å¦‚æœhandleræ‰§è¡Œè€—æ—¶è¿‡é•¿ï¼Œä¸å…è®¸å†æ¬¡è§¦å‘handler)



## lecture 3 OS organization and syscall



## lecture 4 pgtbl



## lecture 5 riscv calling convertion and stack frame

calling convention and stack frames



risc-v ISA different from x86-64 ISA(cisc)

ARM(also RISC) (android)





## lecture 6 isolation & syscall entry_exit

Traps





## lecture 8 page faults

ä¸ºä»€ä¹ˆä¼šæœ‰page faultï¼Ÿ

> æŒ‰ç†è¯´ï¼Œuser programéƒ½æ˜¯é€šè¿‡ç”³è¯·memï¼Œå…ˆåœ¨pagetableä¸­åˆ›å»ºPTEï¼Œä¹‹åæ‰ä¼šè®¿é—®å†…å­˜ï¼Œæ‰ä¼šç”¨å¯¹åº”çš„PTEæ¥è®¿é—®å†…å­˜ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå…ˆåˆ›å»ºPTEï¼Œå†è®¿é—®ã€‚è¿™æ ·åšæ˜¯ä¸ä¼šå­˜åœ¨page faultï¼Œé™¤éè®¿é—®è¶Šç•Œçš„å†…å­˜ã€‚

page faultçš„å­˜åœ¨ï¼Œä¸»è¦æ˜¯ä¸ºäº†lazy allocationï¼Ÿ

With page table and page fault, we have features like:
1. COW fork
2. lazy allocation
3. paging from disk





## lab CoW fork for xv6

é—®é¢˜

> `fork`çš„æ­£å¸¸æµç¨‹ï¼Œchild process copy most PTEs of parent
> ä½†æ˜¯å¤§å¤šæƒ…å†µä¸‹ï¼Œ`fork`ä¹‹åæˆ‘ä»¬ä¼šç«‹åˆ»`exec`ï¼Œç”Ÿæˆæ–°çš„PTEsï¼ŒåŸæ¥æ‹·è´çš„parentçš„PTEå°±æ˜¾å¾—å¤šä½™ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æƒ³è¦é¿å…æ‹·è´PTEs     => ä¸éœ€è¦ç”³è¯·pageï¼Œä¸éœ€è¦copy PTEs
>
> å¦ä¸€äº›æƒ…å†µï¼Œæˆ‘ä»¬éœ€è¦çœŸæ­£ç”³è¯·pageã€å¹¶ä¸”æ‹·è´PTEsï¼š`fork`ä¹‹åçš„ä¸¤ä¸ªè¿›ç¨‹éƒ½ä¼šå¯¹æ•°æ®è¿›è¡Œè¯»å†™ï¼Œè¿™ç§æƒ…å†µå¿…é¡»è¦æ‹·è´PTEsï¼Œå¹¶ä¸”ç”³è¯·æ–°çš„page => éœ€è¦ç”³è¯·pageï¼Œéœ€è¦æ‹·è´PTEs



ç°åœ¨çš„fork

> ç”³è¯·page tableï¼Œæ‹·è´æ‰€æœ‰çš„PTEsï¼Œç”³è¯·å¯¹åº”çš„page



ç”³è¯·page tableï¼Œæ‹·è´æ‰€æœ‰çš„PTEsï¼Œå–æ¶ˆPTE_W bit





shell->fork->exec

> when exec(without decrement the refcnt and kfree)
> child process free all pages shared with shell process(calling kfree without refcnt)
> cause shell crash





`refcnt[]` stores in kernel, recording each page's refcnt of total OS
Elements count should be `PHYSTOP/PGSIZE`



`exit; exec; page fault` stands for some process should free its old page -> `kfree` decrement its old page's refcnt(`with lock`, because running on multi-core) 
decrement page's refcnt without lock, may cause free the same page for twice.



how xv6 bootup?
`kinit` : calling freerange, finally should set refcnt = 0
-> `kvminit` : allocate page for kernel



Pipe -> fork -> read/write

> r/w using pipe, is like copy contents from kernel to user. nothing to do with filesysy, but with **memory copy**.



kernelçŠ¶æ€ä¸‹ï¼Œè¿›è¡Œcopyoutï¼Œä¹Ÿå°±æ˜¯è¦å¯¹user pageè¿›è¡Œwriteï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä»¬éœ€è¦å¯¹user vaè¿›è¡Œcheck
é¦–å…ˆï¼Œæ£€æŸ¥pgtblä¸­æ˜¯å¦å­˜åœ¨vaçš„mappingï¼Œmappingæ˜¯å¦åˆæ³•ï¼Œä»¥åŠæ˜¯å¦PTE_U

å…¶æ¬¡ï¼Œç”±äºæ˜¯forkçš„å­è¿›ç¨‹éœ€è¦copyoutï¼Œå› æ­¤éœ€è¦æ£€æŸ¥PTE_Wï¼Œå¦‚æœPTE_Wï¼Œé‚£ä¹ˆå°±éœ€è¦make a copy of this pageï¼Œè°ƒç”¨cowfault-handlerï¼Œæ‹·è´this pageï¼Œè®¾ç½®æƒé™ï¼›ç„¶åå†è¿›è¡Œæ‹·è´







## lab lazy allocation(2020)

Lazy alloc
> hint: ç¨€ç–mem allocï¼Œä»…ä»…ç”³è¯·è§¦å‘page-faultçš„page

lazy free
> hint: å¯¹äºç¨€ç–ç©ºé—´çš„mem freeï¼Œwalk vaå¤±è´¥çš„æƒ…å†µç›´æ¥continueå¿½ç•¥å³å¯



ç”³è¯·&&é‡Šæ”¾ç©ºé—´ä¹‹åï¼Œå†æ¬¡è®¿é—®è¶Šç•Œå†…å­˜

> è¦ä¹ˆva > p->szï¼Œè¶Šç•Œï¼›è¦ä¹ˆva å°äºstack topï¼Œè¶Šç•Œ
> è¿™ç§æƒ…å†µç›´æ¥Killè¿›ç¨‹å³å¯



`usertests/sbrkarg test FAILED`

sbrkargï¼Œå…ˆç”³è¯·userå†…å­˜ä¸€é¡µpageï¼Œç„¶åopenä¸€ä¸ªæ–‡ä»¶ï¼Œç„¶åä¸æ–­ä»è¿™é¡µpageä¸­æ‹·è´æ•°æ®åˆ°æ–‡ä»¶ä¸­ã€‚

è°ƒç”¨é“¾`sys_write -> filewrite -> writei -> either_copyin -> copyin -> walkaddr` 
è¿™ä¸ªæ—¶å€™æˆ‘ä»¬æ²¡æœ‰è®¿é—®è¿‡è¿™é¡µpageï¼Œå› æ­¤æ²¡æœ‰è§¦å‘page-faultï¼Œä»è€Œæ²¡æœ‰è§¦å‘å¯¹åº”çš„lazy_allocï¼Œæ‰€ä»¥å¯¹åº”çš„PTEå¹¶ä¸å­˜åœ¨ï¼Œwalkaddrä¼šè¿”å›0
è¿™ä¸ªæ—¶å€™æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨è§¦å‘lazy_allocï¼Œç„¶åé‡æ–°walkå³å¯å®Œæˆ`ä»userå†…å­˜æ‹·è´æ•°æ®åˆ°æ–‡ä»¶`



ç±»ä¼¼çš„ï¼Œ`pipe failed`æ˜¯å› ä¸ºæ‹·è´å†…å­˜åˆ°user spaceï¼Œå½“user va walkaddrè¿”å›0çš„æ—¶å€™ï¼Œéœ€è¦æ‰‹åŠ¨lazy_alloc



ç®€å•æ€»ç»“ä¸€ä¸‹sbrkargçš„ä¸¤ä¸ªé”™è¯¯åŸå› 
æœ¬è´¨ä¸Šæ˜¯ï¼Œsbrkç”³è¯·å†…å­˜ä¹‹åï¼ˆç”±äºlazy_allocï¼‰ï¼Œæ²¡æœ‰access this pageï¼Œå¯¼è‡´åç»­æ— è®º read/write this pageï¼Œå®é™…ä¸Šéƒ½æ²¡æœ‰åˆ†é…physical page
è¿™ä¸ªæ—¶å€™æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨ä¿®æ”¹copyin/copyoutï¼Œå½“walkaddrè¿”å›0çš„æ—¶å€™ï¼Œæ‰‹åŠ¨è§¦å‘lazy_allocï¼Œè¿›è¡ŒçœŸå®çš„å†…å­˜åˆ†é…ï¼Œå¹¶ä¸”install å¯¹åº”çš„PTEï¼Œè¿™æ ·åç»­çš„å·¥ä½œæ‰èƒ½æ­£å¸¸å±•å¼€ã€‚

Ref: [link1](http://xiongchen.cc/posts/6.s081-lab-5/) [link2](https://chenlangping.github.io/2021/04/19/xv6-2020-lab5%E8%A7%A3%E6%9E%90/)



ğŸ˜…

sbrkargè¿‡äº†ä¹‹åï¼ŒcopyinåˆæŒ‚äº†







## lecture 9 interrupts



uartinit

> å¯¹uartèŠ¯ç‰‡è¿›è¡Œè®¾ç½®ï¼Œä»è€ŒuartèŠ¯ç‰‡å¯ä»¥ç”Ÿæˆinterrupt



PLIC

> å¯¹PLICè¿›è¡Œprogramï¼Œä»è€Œå¯ä»¥æ¥å—æ¥è‡ªUARTè®¾å¤‡çš„interrupt
> ä¼šé€šçŸ¥æ‰€æœ‰çš„CPUï¼Œä½†æ˜¯æœ€ç»ˆåªæœ‰ä¸€ä¸ªCPUä¼šå¤„ç†è¯¥intr



å¯¹each CPUè¿›è¡Œè®¾ç½®

> å‘PLICè¡¨æ˜ï¼Œè‡ªå·±ï¼ˆeach CPUï¼‰å¯¹æ¥æ”¶ä¸­æ–­æ„Ÿå…´è¶£



ç®€è¨€ä¹‹ï¼Œ
å¯¹è®¾å¤‡è¿›è¡Œç¼–ç¨‹ï¼Œä»¥äº§ç”Ÿä¸­æ–­
å¯¹PLICç¼–ç¨‹ï¼Œåœ¨å„ä¸ªCPUä¸Šä¼ é€’ä¸­æ–­
å¯¹æ¯ä¸ªCPUçš„å¯„å­˜å™¨`SSTATUS`è¿›è¡Œè®¾ç½®ï¼Œå¯åŠ¨æ¥æ”¶ä¸­æ–­ï¼ˆå¦‚æœè¿™ä¸ªæ—¶å€™PLICæœ‰å°šæœªå¤„ç†çš„intrï¼Œé‚£ä¹ˆè¿™ä¸ªcoreå°±ä¼šæ¥æ”¶intrï¼‰



1 device and cpu runs parallel (producer/consumer parallelism)
2 intr stops the current program

> if in user space, its ok
> if in kernel space, sometime we need to enable/disable intr, to make  code sequences atomicï¼Œç¡®ä¿ä»£ç æ˜¯åŸå­çš„

3 intr handler

> top driver and bottom driver can run on different CPUs, running parallel (using lock)





shellæ˜¾ç¤º$çš„è¿‡ç¨‹

> è°ƒç”¨printf -> write -> sys_write -> consolewrite -> copyin( from user space to kernel) -> `uartputc`(å½“å‰CPUè·å–uartè®¾å¤‡çš„lockï¼Œå¦‚æœuart bufferæœ‰ç©ºä½™ï¼Œé‚£ä¹ˆå°±å†™å…¥åˆ°è®¾å¤‡bufferï¼Œå¹¶ä¸”`uartstart`å°†bufferä¸­çš„æ•°æ®å†™å…¥åˆ°è®¾å¤‡å¯„å­˜å™¨ -> æ˜¾ç¤º)



é”®ç›˜typeå­—ç¬¦ï¼Œæœ€ç»ˆå›æ˜¾çš„è¿‡ç¨‹

> `uartintr`uartè®¾å¤‡äº§ç”Ÿintrï¼Œå­—ç¬¦åœ¨è®¾å¤‡çš„å¯„å­˜å™¨ä¸­ -> PLIC -> CPUæ¥æ”¶ä¸­æ–­ï¼Œä»å¯„å­˜å™¨è¯»å–å­—ç¬¦`uartgetc` ->`consoleintr` å°†å­—ç¬¦ä¸²å†™å…¥åˆ°consoleçš„input bufferä¸­ï¼Œå¹¶`consoleputc`è¿›è¡Œå›æ˜¾ç»™ç”¨æˆ· ï¼ˆå­˜åˆ°console input bufferæ˜¯ä¸ºäº†`consoleread`ï¼‰







Ref https://pdos.csail.mit.edu/6.S081/2021/lec/l-interrupt.txt



Producer/consumer parallelism
to decouple, use a buffer in driver

```
Producer/consumer parallelism
  For printing
    shell is producer
    device is consumer
  To decouple the two:
    a buffer in the driver
      top-half puts chars into buffer
        wait if there is no room
	runs in the context of the calling process
      bottom half remove chars from buffer
        interrupt handler wakes up producers # å°†bufferä¸­çš„æ•°æ®å¤„ç†ä¹‹åï¼Œç”¨Interruptè§¦å‘producer
	may not run the context of the shell
  Note: bottom half and top half may run in parallel on different CPUs
    We will get to this in a later lecture
```



```
Polling versus interrupts
  Polling rather than interrupting, for high-rate devices
  Interrupt for low-rate devices, e.g. keyboard
    constant polling would waste CPU
  Switch between polling and interrupting automatically
    interrupt when rate is low (and polling would waste CPU cycles)
    poll when rate is high  (and interrupting would waste CPU cycles)
```





## lecture 10 multiprocessors and locking

ref https://pdos.csail.mit.edu/6.S081/2021/lec/l-lockv2.txt

lockä¸æ­¢æ˜¯åœ¨multithreadä¸‹ä¸ºäº†ä¿æŠ¤user programï¼Œæ›´é‡è¦çš„æ˜¯ multi-core çš„æƒ…å†µä¸‹ä¿æŠ¤kernel data

ä¸ºå•¥éœ€è¦lock

> ```
>     we need locks for correctness
>     but loose performance (kfree is serialized)
> ```





lockå¦‚ä½•å®ç°ï¼Ÿ

> ä¸èƒ½åƒä¸‹é¢é‚£æ ·ï¼Œå› ä¸ºAå’ŒBæœ‰data raceï¼›æ¯”å¦‚ä¸¤ä¸ªcoreä¸Šï¼Œéƒ½è¿è¡Œå®Œäº†Aï¼Œå³å°†è¿è¡ŒBï¼Œé‚£ä¹ˆä¸¤ä¸ªthreadéƒ½ä¼šè·å–lockï¼Œåç»­çš„æ“ä½œå°±å¯èƒ½å¯¼è‡´broken data
>
> å¦‚ä½•å®ç°ï¼Ÿ
> ä¾èµ–äºaomit instructionï¼Œä¼šlock addr globally(å…¶ä»–coreæ— æ³•è¯»å†™addr)

```
How to implement locks?
  why not:
    struct lock { int locked; }
    acquire(l) {
      while(1){
        if(l->locked == 0){ // A
          l->locked = 1;    // B
          return;
        }
      }
    }
  oops: race between lines A and B
  how can we do A and B atomically?

Atomic swap instruction:

  a5 = 1
  s1 = &lk->locked
  amoswap.w.aq a5, a5, (s1)

  does this in hardware:
    lock addr globally (other cores cannot use it)
    temp = *s5
    *addr = a5
    a5 = temp
    unlock addr
```





Xv6 spinlock impl

> é¦–å…ˆï¼Œxv6çš„acquire(l) æ˜¯spin lock
> push_off()çš„ä½œç”¨ï¼Œdisable interrupts
> Release()ï¼Œlk->locked=0ï¼Œenable interrupts



æŒ‡ä»¤é‡æ’

> ä½¿ç”¨`__sync_synchronize()`æ¥é¿å…é‡æ‹
> ä¸è¿‡é€šå¸¸æƒ…å†µä¸‹ä¸éœ€è¦ä½¿ç”¨è¿™ä¸ªå‡½æ•°æ¥é¿å…é‡æ‹ï¼Œå› ä¸ºlockçš„acquireå’Œreleaseå·²ç»å†…éƒ¨ä½¿ç”¨äº†
> å¦‚æœæƒ³å†™å‡º"lock-free" codeçš„æ—¶å€™ï¼Œæ‰ä¼šéœ€è¦ç”¨åˆ°`__sync_synchronize()`

```
  release()'s call to __sync_synchronize() prevents re-order
    compiler won't move a memory reference past a __sync_synchronize()
    and (may) issue "memory barrier" instruction to tell the CPU
  acquire()'s call to __sync_synchronize() has a similar effect:
  if you use locks, you don't need to understand the memory ordering rules
    you need them if you want to write exotic "lock-free" code

```



Spin lock

> spin lockä¼šæµªè´¹cpuï¼Œå› æ­¤spin lockä»…ä»…é€‚ç”¨äºçŸ­æœŸæŒæœ‰ï¼Œä¸»è¦æ˜¯ä¸ºäº†é™ä½cpu yieldçš„å¼€é”€

```
Why spin locks?
  don't they waste CPU while waiting?
  why not give up the CPU and switch to another process, let it run?
  what if holding thread needs to run; shouldn't waiting thread yield CPU?
  spin lock guidelines:
    hold spin locks for very short times
    don't yield CPU while holding a spin lock
  systems provide "blocking" locks for longer critical sections
    waiting threads yield the CPU
    but overheads are typically higher
    you'll see some xv6 blocking schemes later
```



## letcure 11 thread switching

notes https://pdos.csail.mit.edu/6.S081/2021/lec/l-threads.txt



è§†é¢‘é‡Œé¢22åˆ†é’Ÿè®²çš„ç²¾å½©
Scheduler çš„å·¥ä½œ
xv6çš„è¿›ç¨‹åˆ‡æ¢ï¼Œæ€»æ˜¯ä»process Açš„user stackåˆ°kernel stackï¼Œç„¶ååˆ‡æ¢åˆ°process Bçš„kernel stackï¼Œç„¶åå†å›åˆ° process B çš„ user stackï¼Œç„¶åç”¨trapframeæ¢å¤å¯¹åº”çš„regs



ï¼ˆå®é™…ä¸Šå¯ä»¥æœ‰æ›´å¥½çš„æ–¹æ¡ˆï¼Œç›´æ¥ä»user process A ä¸é€šè¿‡kernel stackï¼Œç›´æ¥switchåˆ°user process Bï¼‰



å½“ä¸€ä¸ªprocess ä»user space ç”±äºsyscall æˆ–è€…intrç­‰åˆ‡æ¢åˆ°kernel spaceçš„æ—¶å€™ï¼Œtarmpolineå°†user regs ä¿å­˜åœ¨trapframeé‡Œé¢
åœ¨kernel stackä¸‹ï¼Œå¦‚æœå‘ç”Ÿswitchï¼Œé‚£ä¹ˆä¼šå°†kernel thread registers ä¿å­˜åœ¨  in the process contextä¸­ï¼ˆwhen kernel thread switch to the scheduler threadï¼‰

> **each process has two threads**
> a user level thread
> and a kernel level thread
>
> one process only execute in user space , or executing in the kernel, but never both.



> åœ¨proc.hé‡Œé¢ï¼Œæ¯ä¸ªè¿›ç¨‹éƒ½æœ‰è‡ªå·±çš„
> 1 struct contextï¼Œç”¨æ¥ä¿å­˜å†…æ ¸çº¿ç¨‹å¯„å­˜å™¨( kernel thread registers )
> 2 kstackï¼Œä¿å­˜çš„æ˜¯kernel stackçš„va



ä½†æ˜¯xv6çš„kernel swtichï¼Œç”šè‡³ä¸èƒ½åœ¨kernel spaceä¸‹ç›´æ¥switchåˆ°å¦å¤–ä¸€ä¸ªkernel processï¼Œè€Œæ˜¯åªèƒ½switchåˆ°the scheduler thread ï¼ˆè°ƒåº¦å™¨çº¿ç¨‹ï¼‰



æ¯ä¸ªCPUç‹¬æœ‰ä¸€ä¸ªschedulerï¼Œä»¥åŠå¯¹åº”çš„scheduler stack ( set up in `start.c`, very early when CPU boots on)





`$ra`å°†æ˜¯å†æ¬¡è¢«æ‰§è¡Œçš„ç‚¹ï¼Œè€Œä¸æ˜¯`$pc`







åœ¨ä¸€ä¸ªcpuä¸Šï¼Œthreadå‘ç”Ÿåˆ‡æ¢çš„è¯¦ç»†è¿‡ç¨‹ï¼ˆæ¯”å¦‚timeintrï¼‰

1 timeintr æ—¶é’Ÿä¸­æ–­ ->
2 å½“å‰è¿›ç¨‹æ‰§è¡Œtrapoline.S çš„ `uservec` ->
3 åˆ‡æ¢åˆ°kernel spaceï¼Œæ‰§è¡Œ`usertrap()` ->
4 which_dev == 2ï¼Œå½“å‰è¿›ç¨‹æ”¾å¼ƒCPUï¼Œæ‰§è¡Œ`yield()` ->
5 `yield()`ä¸­ï¼Œä¿®æ”¹å½“å‰procçš„stateï¼Œæ‰§è¡Œ`sched()` ->
6 `sched()`ä¸­ï¼Œè°ƒç”¨`swtch.S`ï¼Œå°†å½“å‰CPUçš„å„ç±»å¯„å­˜å™¨ï¼ˆä¹Ÿå°±æ˜¯ kernel spaceä¸‹çš„registersï¼‰ä¿å­˜åˆ°å½“å‰è¿›ç¨‹çš„contextä¸­ï¼Œç„¶åå°†å½“å‰CPUçš„contextçš„æ•°æ®ï¼ŒåŠ è½½åˆ°å½“å‰CPUçš„å¯„å­˜å™¨ä¸­ï¼ˆCPUçš„contextå®é™…ä¸Šä¿å­˜çš„æ˜¯schedulerçš„contextï¼‰
7 `scheduler()`ä¸­ï¼Œç­›é€‰æ‰€æœ‰çš„processï¼Œå¦‚æœå¯ä»¥è°ƒåº¦ï¼Œå°±é€‰æ‹©ï¼Œç„¶åswtchï¼ˆè¿™æ¬¡swtchï¼Œæ˜¯æŠŠschedulerçš„regsä¿å­˜åˆ°cpuçš„contextï¼Œç„¶åä»å¯¹åº”processçš„contextåŠ è½½regsï¼‰**but scheduler never returns**, because context.ra is the return address



ref https://pdos.csail.mit.edu/6.S081/2021/lec/l-threads.txt



## review trampoline and proc



### in proc.h

`proc.h`

é‡Œé¢çš„trapframeï¼Œæ˜¯ä¸ªstructï¼Œ
æ‰§è¡Œçš„æ˜¯

å®é™…ä¸Šä¸€ä¸ªprocessçš„trapframeï¼Œæ— è®ºåœ¨user space è¿˜æ˜¯ kernel spaceï¼Œ**åŒä¸€æ—¶åˆ»åªæœ‰å…¶ä¸­çš„ä¸€åŠ**ä¼šå­˜å‚¨æ•°æ®ï¼Œå¦å¤–ä¸€åŠå¤„äºé—²ç½®çŠ¶æ€ã€‚
ï¼ˆå½“å¤„äºuser spaceçš„æ—¶å€™ï¼Œå­˜å‚¨çš„æ˜¯kernel_*ï¼›å¤„äºkernel spaceçš„æ—¶å€™ï¼Œå­˜å‚¨çš„æ˜¯userç›¸å…³çš„regsï¼‰



### in trampoline.S

code to switch between user and kernel space



`uservec()`ï¼Œæ±‡ç¼–å‡½æ•°
ç”¨å¤„ï¼š
1 Save user registers in the trapframe ï¼ˆä¿å­˜user regsåˆ°trapframeï¼‰
2 initialize registers from trapframe's kernel\_\* ï¼ˆä»trapframeä¸­çš„kernel\_\*åŠ è½½æ•°æ®åˆ°å¯„å­˜å™¨ä¸­ï¼‰
3 è·³åˆ° kernel_satpï¼Œä¹Ÿå°±æ˜¯è°ƒç”¨ `usertrap()`



`userret(TRAPFRAME, pagetable)`
æ±‡ç¼–å‡½æ•°
load all kinds of user registers from user page table memory to CPU's regsiters

1`usertrapret()` ä¿å­˜æŠŠkernel\_\*ç›¸å…³çš„å¯„å­˜å™¨ä¿å­˜åˆ°trapframeä¸­
2 `userret`ä»trapframeä¸­åŠ è½½user registers
3 `userret`switch to user page table
4 `userret`enter user space



### in swtch.S

Assambly function
Swtch, `void swtch(struct context *old, struct context *new)`
å½“å‘ç”Ÿschedulerçš„æ—¶å€™ï¼Œéœ€è¦åœ¨kernel stackä¸‹è¿›è¡Œswitch
è¿™ä¸ªfunctionçš„ä½œç”¨æ˜¯ï¼Œä¿å­˜å½“å‰çš„ registers åˆ°oldï¼Œä»newä¸­åŠ è½½æ•°æ®åˆ°registersä¸­



## lab multithreads



### user level thread switch

`thread_switch` save regs of the thread swtiched away from, restores regs of the thread being switched to.



æœ‰æ ˆåç¨‹è€Œè¨€ï¼Œæœ€é‡è¦çš„ä¸¤ä¸ªå¯„å­˜å™¨
`$sp` stack pointer
`$ra` æ‰§è¡Œåç¨‹è®¾å®šçš„function



### using threads

using threads in hashtable to improve performance



### barrier

```cpp
  pthread_mutex_lock(&bstate.barrier_mutex);
  bstate.nthread++;
  if(bstate.nthread == nthread){
    bstate.round++;
    bstate.nthread = 0;
    pthread_cond_broadcast(&bstate.barrier_cond);
  }
  else{
    pthread_cond_wait(&bstate.barrier_cond, &bstate.barrier_mutex);
  }
  pthread_mutex_unlock(&bstate.barrier_mutex);
```



`cond`çš„ä½œç”¨ï¼Œç”¨äºå­˜å‚¨ç”±äºcon_waitå¯¼è‡´é˜»å¡çš„threadï¼Œå¹¶ä¸”è‡ªåŠ¨é‡Šæ”¾lockï¼Œæ­¤æ—¶thread ä¼šç”±äºcondè€Œå¤„äºé˜»å¡çŠ¶æ€ï¼ˆcondæ›´åƒæ˜¯ä¸€ä¸ªå®¹å™¨ï¼Œç”¨äºå­˜å‚¨ blocked threadï¼‰



`cond_wait(cond, mutex)`ï¼Œç­‰å¾…condä¸»åŠ¨å‘å‡ºä¿¡å·`cond_signal()` æˆ–è€…å¹¿æ’­`cond_boardcast()`ï¼Œç„¶åç»§ç»­æ‰§è¡Œï¼›å¦åˆ™**å°†ä¸€ç›´ç­‰å¾…**ã€‚å°†å½“å‰threadå­˜å‚¨åˆ°condä¸­ï¼Œå¹¶ä¸”é‡Šæ”¾lockã€‚æ­¤æ—¶é‡Šæ”¾lockä¹‹åï¼Œthreadä»ç„¶é˜»å¡åœ¨condã€‚
è¢«condé˜»å¡çš„threadï¼Œå¯ä»¥è¢«`cond_signal()`  ä»¥åŠ `cond_broadcast()`å”¤é†’ã€‚å”¤é†’åï¼Œå½“å‰threadä¼šç»§ç»­å°è¯•è·å–lock



`cond_wait(cond, mutex) = unlock + just wait + lock`



`cond_boardcast(cond)`å”¤é†’é˜»å¡åœ¨condå˜é‡ä¸­çš„æ‰€æœ‰threadã€‚
`cond_signal(cond)`å”¤é†’é˜»å¡åœ¨condå˜é‡ä¸­çš„è‡³å°‘ä¸€ä¸ªthreadã€‚



https://www.cnblogs.com/xudong-bupt/p/6707070.html





lock

cnt++ <- ç”±äºcntå˜é‡ä¼šå­˜åœ¨data raceï¼Œå› æ­¤éœ€è¦åŠ lock

if cntå˜é‡ æ¡ä»¶æ»¡è¶³ then { cnt = 0 å½’é›¶å˜é‡ï¼Œcond_boardcast }
else cntå˜é‡ æ¡ä»¶ä¸æ»¡è¶³ then { cond_wait }

unlock

> å› ä¸ºç”¨æˆ·å†™ç¨‹åºçš„æ—¶å€™é€šå¸¸æ˜¯å‘ç°å½“å‰ä¸€äº›å˜é‡çš„å€¼æ¯”å¦‚è¯´å˜é‡aå¹¶ä¸æ»¡è¶³æœŸå¾…çš„æ¡ä»¶ï¼Œæ‰€ä»¥é€‰æ‹©è°ƒç”¨cond_waitæŠŠå½“å‰çº¿ç¨‹æŒ‚èµ·ï¼ŒæœŸå¾…åˆ«çš„çº¿ç¨‹ä¿®æ”¹açš„å€¼ã€‚å˜é‡aè‡ªç„¶æ˜¯å¤šä¸ªçº¿ç¨‹ä¹‹é—´å…±äº«çš„ï¼Œæ‰€ä»¥æœ¬æ„æ˜¯è®©ä½ ç”¨è¿™ä¸ªmutexä¿æŠ¤açš„ï¼Œè€Œä¸æ˜¯è¯´pthread_cond_waitçš„å†…éƒ¨å®ç°éœ€è¦ç”¨è¿™ä¸ªmutexä¿æŠ¤ä»€ä¹ˆã€‚
>
> 
>
> ä½œè€…ï¼šç™½å¦‚å†°
> é“¾æ¥ï¼šhttps://www.zhihu.com/question/24116967/answer/405994073
> æ¥æºï¼šçŸ¥ä¹
> è‘—ä½œæƒå½’ä½œè€…æ‰€æœ‰ã€‚å•†ä¸šè½¬è½½è¯·è”ç³»ä½œè€…è·å¾—æˆæƒï¼Œéå•†ä¸šè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚





best practice https://zhuanlan.zhihu.com/p/55123862

> æŒ‡å‡ºåœ¨å…·ä½“å®ç°ä¸­ï¼Œä¸Šè¿°æƒ…å†µå¯èƒ½ä¼šå¤šçš„ä¸€æ¬¡çº¿ç¨‹ä¸Šä¸‹åˆ‡æ¢åœ¨ pthread ä¸­å·²ç»è¢«ä¼˜åŒ–ï¼Œæ‰€ä»¥ä¸ä¼šå­˜åœ¨è¿™ä¸ªé—®é¢˜ã€‚





è¿™ä¸ªä»»åŠ¡è¦æ±‚è§£å†³ä¸€ä¸ªç¨‹åºä¸­çš„åŒæ­¥é—®é¢˜ã€‚æ ¸å¿ƒæ˜¯ç†è§£pthread_cond_waitè¿™ä¸ªå‡½æ•°çš„åŠŸèƒ½ï¼Œpthread_cond_waitè¿™ä¸ªå‡½æ•°åœ¨è°ƒç”¨æ—¶ä¼šé‡Šæ”¾é”ï¼Œéšå«çš„æ„æ€å°±æ˜¯åœ¨æ‰§è¡Œè¿™ä¸ªå‡½æ•°å‰å¿…é¡»å…ˆé”ä¸Šï¼›å‡½æ•°åœ¨é˜»å¡ç»“æŸè¢«å”¤é†’æ—¶ä¼šè·å–é”ï¼Œéšå«çš„æ„æ€å°±æ˜¯åœ¨è¿™ä¸ªå‡½æ•°è°ƒç”¨ç»“æŸåéœ€è¦é‡Šæ”¾é”ï¼š

https://www.cnblogs.com/YuanZiming/p/14244119.html



https://pubs.opengroup.org/onlinepubs/007908799/xsh/pthread_mutex_lock.html

https://pubs.opengroup.org/onlinepubs/007908799/xsh/pthread_cond_broadcast.html

https://pubs.opengroup.org/onlinepubs/007908799/xsh/pthread_cond_wait.html

https://pubs.opengroup.org/onlinepubs/007908799/xsh/pthread_cond_wait.html





## lecture 13 sleep & wakeup

Notes https://pdos.csail.mit.edu/6.S081/2020/lec/l-coordination.txt



`uart.c`

`uartwrite()` é€šè¿‡whileå¾ªç¯ï¼Œå¾ªç¯ä½“å†…éƒ¨ä¸æ–­æ£€æŸ¥ç¡¬ä»¶ä»»åŠ¡`tx_done`æ˜¯å¦å®Œæˆï¼Œç„¶åå‘é€æ–°çš„THRï¼Œä»¥ä¾›ç¡¬ä»¶æ‰“å°
`uartintr()` æ¯æ¬¡ç¡¬ä»¶ä»»åŠ¡å®Œæˆçš„æ—¶å€™ï¼Œå°±ä¼šè§¦å‘è¿™ä¸ª`intrhandler`ï¼Œç„¶åä¿®æ”¹`tx_done`ï¼Œä»è€Œå”¤é†’`uartwrite()`



### sleep  and wakeup

> `write routine`
>
> ```c
> void 
> uartwrite(char buf[], int n)
> {
>   acquire(&uart_tx_lock);
>   int i = 0;
>   while(i < n){
>     // where here is a while loop? considering this case, more than 1 write routine sleep here.
>     while(tx_done == 0){  // ä¸æ–­æ£€æŸ¥æ¡ä»¶(ç”±äºè¢«å”¤é†’ä¹‹åï¼Œå½“å‰processæœªå¿…èƒ½è·å–lockï¼Œå¯èƒ½åªæœ‰ä¸€ä¸ªprocessè·å–lockï¼Œå› æ­¤éœ€è¦ä¸æ–­æ£€æŸ¥)
>       sleep(&tx_chan, &uart_tx_lock); // é‡Šæ”¾lock, å°†å½“å‰proc.Stateè®¾ç½®æˆtx_chanï¼Œè¿›è¡Œsleep, è¢«å”¤é†’ä¹‹åé‡æ–°è·å–lock
>     }
>     WriteReg(THR, buf[i]);
>     i += 1;
>     tx_done = 0;
>   }
>   release(&uart_tx_lock);
> }
> ```
>
> 
>
> `intr routine`
>
> ```c
> void
> uartintr(void)
> {
>   acquire(&uart_tx_lock);
>   if(ReadReg(LSR) & LSR_TX_IDLE){  // æ£€æŸ¥ç¡¬ä»¶æ¡ä»¶
>     tx_done = 1; // æ¡ä»¶æ»¡è¶³ï¼Œå”¤é†’æ‰€æœ‰çš„ write_routine
>     wakeup(&tx_chan); // éå†æ‰€æœ‰çš„processï¼Œå¯¹äºstate == tx_chançš„processï¼Œreset it's state
>   }
>   release(&uart_tx_lock);
> }
> ```
>
> 



### lost wakeup problem

> ```c
> void
> broken_sleep(void *chan)
> {
>   struct proc *p = myproc();
>   
>   // Must acquire p->lock in order to 
>   // change p->state and then call sched.
>   acquire(&p->lock);
>   
>   // Now sleep.
>   p->chan = chan;
>   p->state = SLEEPING;
>   
>   sched();
>   
>   // Tidy up.
>   p->chan = 0;
>   release(&p->lock);
> }
> 
> void 
> uartwrite(char buf[], int n)
> {
>   acquire(&uart_tx_lock);
>   int i = 0;
>   while(i < n){
>     while(tx_done == 0){
>       release(&uart_tx_lock);
>       // INTERRUPT HERE 
>       // å¦‚æœsleepä¸éœ€è¦lockï¼Œè¿™ç§æƒ…å†µä¸‹ä¼šå¯¼è‡´ å”¤é†’ä¸¢å¤±
>       broken_sleep(&tx_chan);
>       acquire(&uart_tx_lock);
>    	}
>    WriteReg(THR, buf[i]);
>    i += 1;
>    tx_done = 0;
>   }
>   release(&uart_tx_lock);
> }
> ```
>
> å¦‚æœè¯´sleepä¸éœ€è¦lockï¼Œåªéœ€è¦chanï¼Œé‚£ä¹ˆå°±ä¼šå¯¼è‡´lose intr problem
>
> åŸå› ï¼š
> å‡è®¾ä¸€ä¸ª`process A`æ‰§è¡Œ`uartwrite`åˆ° `INTERRUPT HERE`çš„ä½ç½®ï¼Œå·²ç»é‡Šæ”¾lockï¼Œä½†æ˜¯è¿˜æ²¡æœ‰è¿›å…¥sleepçŠ¶æ€
> æ­¤æ—¶å¦å¤–ä¸€ä¸ª`process B`æ‰§è¡Œ`uartintr`ï¼Œç”±äºlockå·²ç»è¢«é‡Šæ”¾ï¼Œæ­¤æ—¶`uartintr`å¯ä»¥é¡ºåˆ©æ‰§è¡Œï¼Œè·å–lockï¼Œå¹¶ä¸”å”¤é†’æ‰€æœ‰çš„tx_chançš„è¿›ç¨‹ã€‚
>
> Aå…ˆsleepï¼ŒBåå”¤é†’ï¼Œåº”è¯¥å”¤é†’ä½†æ˜¯å´æ²¡æœ‰å”¤é†’Aè¿›ç¨‹ã€‚è¿™å°±æ˜¯å”¤é†’ä¸¢å¤±
>
> å¦‚ä½•è§£å†³ï¼Ÿ
> å…³é”®æ˜¯è¦ä¿è¯`release lock`å’Œ`sleep on tx_chan`çš„åŸå­æ€§
>
> å¯¹æ¯”sleepçš„ä»£ç 
>
> 1 é‡Šæ”¾uartçš„è®¾å¤‡lock( uartè®¾å¤‡ç°åœ¨å¯ä¾›å…¶ä»–è¿›ç¨‹ä½¿ç”¨ )ï¼Œè·å–å½“å‰è¿›ç¨‹çš„lock ( å½“å‰è¿›ç¨‹éœ€è¦sleep ) ->
> 2 è®¾ç½®å½“å‰è¿›ç¨‹sleepï¼Œsched() åˆ°å…¶ä»–è¿›ç¨‹ ->
> 3 å†æ¬¡è¢«å”¤é†’ï¼Œé‡Šæ”¾è¿›ç¨‹lockï¼Œè·å–è®¾å¤‡lock
>
> ```c
> // Atomically release lock and sleep on chan.
> // Reacquires lock when awakened.
> void
> sleep(void *chan, struct spinlock *lk)
> {
>   struct proc *p = myproc();
>   
>   // Must acquire p->lock in order to
>   // change p->state and then call sched.
>   // Once we hold p->lock, we can be
>   // guaranteed that we won't miss any wakeup
>   // (wakeup locks p->lock),
>   // so it's okay to release lk.
>   if(lk != &p->lock){  //DOC: sleeplock0
>     acquire(&p->lock);  //DOC: sleeplock1
>     release(lk);
>   }
> 
>   // Go to sleep.
>   p->chan = chan;
>   p->state = SLEEPING;
> 
>   sched();
> 
>   // Tidy up.
>   p->chan = 0;
> 
>   // Reacquire original lock.
>   if(lk != &p->lock){
>     release(&p->lock);
>     acquire(lk);
>   }
> }
> ```
>
> 



åœ¨`write routine`
sleepä¸ºä»€ä¹ˆéœ€è¦whileå¾ªç¯

> å¯èƒ½å­˜åœ¨2ä¸ªä»¥ä¸Šçš„`write routine`ã€‚
> å½“`intr`å‘ç”Ÿæ—¶ï¼Œ`intr routine`ä¼šå”¤é†’æ‰€æœ‰`sleep on this chan`çš„routineã€‚
> ä½†æ˜¯`write routine`æ£€æŸ¥çš„æ—¶å€™ä¼šé‡æ–°è·å–`lock`ï¼Œå› æ­¤ï¼Œ`intr`å”¤é†’æ‰€æœ‰`routine`ä¹‹åï¼Œç”±äºåªæœ‰ä¸€ä¸ª`routine`å¯ä»¥æˆåŠŸè·å–`lock`ï¼Œå…¶ä½™æ‰€æœ‰è¢«å”¤é†’çš„`routine`ä¸å¾—ä¸é‡æ–°sleepã€‚
> å› æ­¤éœ€è¦whileå¾ªç¯ï¼Œç›´åˆ°è¢«å”¤é†’ï¼Œå¹¶ä¸”æˆåŠŸè·å–lock





### another example

 ä¸€ä¸ª`pipewrite` å¤šä¸ª`piperead`

> `pipewrite`
>
> ```c
> int
> pipewrite(struct pipe *pi, uint64 addr, int n)
> {
> int i;
> char ch;
> struct proc *pr = myproc();
> 
> acquire(&pi->lock);
> for(i = 0; i < n; i++){
>  while(pi->nwrite == pi->nread + PIPESIZE){
>    if(pi->readopen == 0 || pr->killed){
>      release(&pi->lock);
>      return -1;
>    }
>    wakeup(&pi->nread);
>    sleep(&pi->nwrite, &pi->lock);
>  }
>  if(copyin(pr->pagetable, &ch, addr + i, 1) == -1)
>    break;
>  pi->data[pi->nwrite++ % PIPESIZE] = ch;
> }
> wakeup(&pi->nread); // wakeup all pipe-reader
> release(&pi->lock);
> return i;
> }
> ```
>
> 
>
> `piperead`
>
> ```c
> int
> piperead(struct pipe *pi, uint64 addr, int n)
> {
>   int i;
>   struct proc *pr = myproc();
>   char ch;
> 
>   acquire(&pi->lock);
>   // å¦‚æœæœ‰å¤šä¸ªpipe-readerï¼Œé‚£ä¹ˆæ¯æ¬¡pipe-write walkupï¼Œåªèƒ½æœ‰ä¸ªreaderè·³å‡ºwhileå¾ªç¯ï¼Œæ‰§è¡Œåˆ°release(&pi->lock)ï¼Œå…¶ä»–çš„pipe-readeræ‰èƒ½ç»§ç»­è¿›å…¥whileå¾ªç¯
>   while(pi->nread == pi->nwrite && pi->writeopen){
>     if(pr->killed){
>       release(&pi->lock);
>       return -1;
>     }
>     sleep(&pi->nread, &pi->lock); // sleep, and release pipe lock
>   }
>   for(i = 0; i < n; i++){
>     if(pi->nread == pi->nwrite)
>       break;
>     ch = pi->data[pi->nread++ % PIPESIZE];
>     if(copyout(pr->pagetable, addr + i, &ch, 1) == -1)
>       break;
>   }
>   wakeup(&pi->nwrite);
>   release(&pi->lock);
>   return i;
> }
> ```
>
> 





### Xv6 å¦‚ä½•æ­£ç¡®çš„é‡Šæ”¾ thread/process 

> `exit() kill()`
>
> ä»¥`exit()`ä¸ºä¾‹ï¼Œæ•´ä¸ªçš„æµç¨‹ï¼Œå®é™…ä¸Šæ˜¯ã€Œexit + waitã€ï¼ŒåŒ…æ‹¬ `childprocess.exit() reset process's state; `
> `parentprocess.wait() release childprocess's resources` 
>
> 
>
> exit
> 1 close all files
> 2 reset its working directory
> 3 reparent its child process to init process
> 4 wakeup its parent process
> 5 set its state to `ZOMBIE`
> 6 waiting its parent process to free its resources
> 7 **sched() and never returns, waitint parent process to free its resources**
>
> 
>
> wait
> 1 scan one its child process and state is `ZOMBIE`
> 2 free its `proc`
>
> ä¸€ä¸ªè¿›ç¨‹çš„é€€å‡ºï¼Œä¸ºä»€ä¹ˆè¦åˆ†æˆä¸¤æ­¥çš„å¼‚æ­¥æ“ä½œï¼Ÿ
> ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥åœ¨è¿›ç¨‹é€€å‡ºçš„æ—¶å€™é‡Šæ”¾è¿›ç¨‹çš„èµ„æºï¼Ÿ
> é¦–å…ˆä¸€ä¸ªthreadåŒ…æ‹¬è‡ªå·±çš„stateä»¥åŠè‡ªå·±çš„stackï¼Œå¦‚æœä¸€ä¸ªthreadçš„ç»“æŸå°±é‡Šæ”¾æ‰è‡ªå·±å ç”¨çš„å…¨éƒ¨èµ„æºï¼Œé‚£ä¹ˆæœ¬process å†…éƒ¨çš„å…¶ä»–threadï¼Œå¾ˆå¯èƒ½å°±æ— æ³•ç»§ç»­æ‰§è¡Œï¼ˆæ¯”å¦‚å…¶ä»–threadå¯èƒ½æ­£åœ¨æ‰§è¡Œkernel stackï¼Œæ­¤æ—¶é‡Šæ”¾threadçš„èµ„æºï¼Œå¯èƒ½ä¼šå¯¼è‡´kernelå´©æºƒï¼‰
> å› æ­¤ä¸èƒ½ç›´æ¥é‡Šæ”¾è‡ªå·±çš„èµ„æº



### gentle kill() in xv6/unix

> kill() functionä»…ä»… set è¿™ä¸ªprocessçš„killedæ ‡å¿—ä½ ä»¥åŠ stateï¼Œ
> è€Œä¸æ˜¯ç›´æ¥shutdown this process, in case it's in kernel state and operating some important kernel operations, leads to broken kernel.
>
> è®¾ç½®äº†flagä¹‹åï¼Œå½“`timeintr/intr/syscall`è§¦å‘çš„æ—¶å€™
>
> 
>
> case 1 ç”¨æˆ·è¿›ç¨‹è¿›å…¥trap()çš„æ—¶å€™ï¼Œè°ƒç”¨exit()
> è¢«killçš„ç”¨æˆ·è¿›ç¨‹ï¼Œå¹¶ä¸æ˜¯åœ¨user space ç›´æ¥è¢«shut downï¼Œè€Œæ˜¯å½“å†æ¬¡è§¦å‘syscall æˆ–è€… intr æˆ–è€… timerintrï¼Œä¼šå®‰å…¨çš„é€šè¿‡exit()è¿›è¡Œé€€å‡ºï¼ˆå¯ä»¥é¿å…ç ´ååœ¨kernel spaceä¸‹æ­£åœ¨æ‰§è¡Œé‡è¦çš„æ“ä½œï¼‰
>
> 
>
> case 2 process in kernel space, but sleep, å¯ä»¥ç›´æ¥exit()
> æ¯”å¦‚ä¸€ä¸ªprocessè¯»å–consoleï¼Œä½†æ˜¯ä¸€ç›´æ²¡æœ‰è¾“å…¥ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œä»ç„¶å¯ä»¥ç›´æ¥killæ‰å¤„äºkernel spaceä¸‹sleepçš„process
>
> 
>
> In `kill()`, if it's state is `SLEEPING`, reset to `RUNNABLE`
>
> `piperead()`å¯ä»¥æ£€æŸ¥killedï¼Œç„¶åç›´æ¥return -1ï¼Œè¿”å›åˆ°`trap()`çš„`syscall()`ä¸­ï¼Œç„¶å`exit()`
>
> 
>
> æ€»ä¹‹ï¼Œåœ¨kernel spaceå¤„äºsleepçš„çŠ¶æ€ä¸‹killï¼Œ**èƒ½ä¸èƒ½ç›´æ¥exit()ï¼Œå–å†³äºå½“å‰æ‰§è¡Œçš„kernelæ“ä½œçš„é‡è¦æ€§**ã€‚
> **é‡è¦çš„kernelæ“ä½œï¼Œè¿›è¡Œä¸­ä¸ä¼šæ£€æŸ¥killedï¼Œå®Œæˆæ•´ä¸ªæ“ä½œåæ‰å¯èƒ½æ£€æŸ¥**killed

in real unix OS, there will be user permission check, to prevent kill other user's processes. But in xv6, no user permission check.

In xv6, `init process` is not allowed exit(), see code in `init.c` and `exit():exit will check if it's init process`



## lecture 14 file sys



file sys is about:
1 abstraction
2 crash safety
3 performance { storage devices are slow, buffer cache + concurrency }



CPU access disk ( R/W )

disk is a big array of blocks

index = 0, is boot (one block of code, to boot up the OS)
index = 1, is super block





`bio.c`

Provides functions bellow:
1 `bread()` read a block from disk and cache it in buffer
2 `bwrite()` change the buffer data, write to disk
3 `brelse()` when done with buffer, call brelse





File descriptor layer

å®é™…ä¸Š
fdæ–‡ä»¶æè¿°ç¬¦ä»…ä»…æ˜¯è¿›ç¨‹ç»“æ„ä¸­çš„struct file\*æŒ‡é’ˆæ•°ç»„çš„index
é€šè¿‡indexå¯ä»¥ç›´æ¥è®¿é—®åˆ°è¿›ç¨‹å¯¹åº”çš„file\*

è¿™ä¸€å±‚æ˜¯å¯¹æ–‡ä»¶çš„å°è£…
æ–‡ä»¶æè¿°ç¬¦çš„åˆ†é…ã€å¤åˆ¶ã€å…³é—­ï¼š`filealloc filedup fileclose`
æ–‡ä»¶ä¿¡æ¯çš„è¯»å–ï¼š`filestat fileread filewrite`



directory layer
ç›®å½•ä¹Ÿæ˜¯inodeæ¥è¡¨è¿°çš„ï¼Œå†…éƒ¨å­˜å‚¨çš„æ˜¯`struct dirent`æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ª`entry`

ä¸»è¦åŒ…å«
`dirlookup` åœ¨ç»™å®šçš„ç›®å½•ä¸­æŸ¥æ‰¾ç›®æ ‡æ–‡ä»¶ï¼ˆå¦‚æœæ‰¾åˆ°ç¬¦åˆnameçš„entryï¼Œå°±è¿”å›å¯¹åº”æ–‡ä»¶çš„inodeï¼Œå¹¶å°†poffè®¾ç½®åˆ°å¯¹åº”çš„entryï¼Œä»¥æ–¹ä¾¿æ›´æ”¹æ–‡ä»¶åç§°ï¼‰

`dirlink` åœ¨ç»™å®šçš„ç›®å½•ä¸­æ·»åŠ æ–°çš„entryï¼ˆå¦‚æœæ–‡ä»¶çš„åç§°å·²ç»å­˜åœ¨ï¼Œåˆ™è§†ä½œé”™è¯¯ï¼›å¦‚æœä¸å­˜åœ¨ï¼Œå°±æ‰«æå½“å‰ç›®å½•çœ‹çœ‹æœ‰æ²¡æœ‰ç©ºä½™çš„entryï¼Œå¦‚æœæ²¡æœ‰å°±å¢åŠ æ–°çš„entryï¼Œæœ€åå°†entryè®¾ç½®ä¸ºå¯¹åº”æ–‡ä»¶çš„ä¿¡æ¯ï¼‰



`namei` ä¼ é€’æ–‡ä»¶çš„è·¯å¾„ï¼Œè¿”å›å¯¹åº”æ–‡ä»¶çš„inode

`nameiparent` ä¼ é€’æ–‡ä»¶çš„è·¯å¾„ï¼Œè¿”å›çˆ¶ç›®å½•çš„inodeï¼Œå¹¶ä¸”è¿”å›å¯¹åº”æ–‡ä»¶çš„name

è¿™ä¸¤ä¸ªå‡½æ•°æœ€ç»ˆä¾èµ–äº`namex`æ¥è¿è¡Œ

`namex` åŒ…å«çš„è¿‡ç¨‹
1 path evalutionï¼Œæ ¹æ®è·¯å¾„åï¼Œå†³å®šæœç´¢çš„èµ·å§‹ç›®å½•æ˜¯å½“å‰ç›®å½•è¿˜æ˜¯æ ¹ç›®å½•
2 é€å±‚è§£æï¼Œè§£æå‡ºæ¯ä¸€å±‚ç›®å½•çš„åç§°ï¼Œåœ¨å½“å‰inodeä¸­æŸ¥æ‰¾ç¬¦åˆnameçš„æ–‡ä»¶
3 å¦‚æœæ˜¯`nameiparent`ï¼Œå°±è¿”å›å¯¹åº”parentçš„inode



Inode layer

`dinode` (on-disk, meta-data and data of a file)

`nlink`å­—æ®µ è¡¨æ˜æŒ‡å‘å½“å‰è¿™ä¸ªæ–‡ä»¶çš„ç›®å½•entriesçš„æ•°é‡
`size` data size(bytes)
`addrs` åŒ…å«äº†dataçš„dinode



`inode` (in-memory, meta-data of a file)
`ref`å­—æ®µï¼Œè®°å½•äº†å¼•ç”¨å½“å‰inodeçš„CæŒ‡é’ˆçš„æ•°é‡ï¼ˆ`iget iput`ä¼šåˆ†åˆ«é€šè¿‡è·å–/é‡Šæ”¾æŒ‡å‘å½“å‰inodeçš„æŒ‡é’ˆï¼Œä»è€Œå¢åŠ ref å‡å°‘refï¼‰

é€šè¿‡`iget(dev, ino)`æ¥è®¿é—®å†…å­˜ä¸­çš„inodeï¼ˆä¼˜å…ˆæŸ¥æ‰¾inode cacheï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°±åˆ†é…ä¸€ä¸ªinodeï¼Œsetéƒ¨åˆ†åŸºæœ¬ä¿¡æ¯ï¼‰
`ilock`é”å®šç»™å®šçš„inodeï¼Œå¦‚æœå½“å‰inodeè¿˜æ²¡æœ‰ä»diskä¸­åŠ è½½ï¼Œå°±read diskï¼Œè·å–dinodeçš„ä¿¡æ¯ï¼Œæ‹·è´åˆ°inodeä¸­



the inode cache
Main perpose: synchronize access by multiple processesï¼Œä¸»è¦ç›®çš„æ˜¯ä¸ºäº†å¹¶å‘æ§åˆ¶ï¼Œæ¬¡è¦ç›®çš„æ‰æ˜¯cacheåŠ é€Ÿ
Secondary: cache

Xv6 inode cache is write-through









## lab locks



### memory allocator

```c
struct spinlock{
  uint64 n;   // acquireçš„è°ƒç”¨æ¬¡æ•°
  uint64 nts; // ç´¯è®¡çš„test_and_set loopæ¬¡æ•°
}// n å’Œ nts éƒ½éœ€è¦å‰åç›¸å‡è®¡ç®—å‡ºæ¥test()è¿‡ç¨‹çš„å®é™…æ¬¡æ•°
```



```
The root cause of lock contention in kalloctest is that kalloc() has a single free list, protected by a single lock. To remove lock contention, you will have to redesign the memory allocator to avoid a single lock and list. 

The basic idea is to maintain a free list per CPU, each list with its own lock. Allocations and frees on different CPUs can run in parallel, because each CPU will operate on a different list. 

The main challenge will be to deal with the case in which one CPU's free list is empty, but another CPU's list has free memory; in that case, the one CPU must "steal" part of the other CPU's free list. Stealing may introduce lock contention, but that will hopefully be infrequent.
```



```
Your job is to implement per-CPU freelists, and stealing when a CPU's free list is empty. You must give all of your locks names that start with "kmem". That is, you should call initlock for each of your locks, and pass a name that starts with "kmem". Run kalloctest to see if your implementation has reduced lock contention.
```



key points
1 get cpu id with `cpu()`
2 do not forget to break the for loop when `kfree()` steal one page from other cpus' freelist



### buffer cache

å®é™…ä¸Šæ˜¯ä¸€ä¸ªbucketçº§åˆ«lockçš„lru cache

```
Modify bget and brelse so that concurrent lookups and releases for different blocks that are in the bcache are unlikely to conflict on locks (e.g., don't all have to wait for bcache.lock). You must maintain the invariant that at most one copy of each block is cached. When you are done, your output should be similar to that shown below (though not identical). Make sure usertests still passes. make grade should pass all tests when you are done.


```



```
We suggest you look up block numbers in the cache with a hash table that has a lock per hash bucket.
```



`test0`ä¼šåˆšå¥½åˆ›å»º3ä¸ªfileï¼Œæ¯ä¸ªfileåŒ…æ‹¬10ä¸ªblockï¼Œåˆšå¥½è£…æ»¡bcacheã€‚
test0ä¸ä¼šå‘ç”Ÿä¸€ä¸‹æƒ…å†µï¼š
1 2 processes use same block
2 miss the cache, and find an unused block to replace
3 block number may hash to the same slot in a hash table



13ä¸ªlock
å¯¹åº”13ä¸ªLRU head

å®é™…ä¸Šå¾ˆç®€å•ï¼Œåªéœ€è¦å¯¹blockno è¿›è¡Œhashå³å¯



## lab file sys

### bigfile

using three-level direcotry

`bmap` for one inode, install addrs for `block num n` (if not allocated, then allocate and install)

`itrunc` (for one inode, remove all addrs and recycle this file's data blocks)



### symbolic links

Hard link <-> soft link https://www.jianshu.com/p/c10dc8136170

> hard link, create an entry <-> binded with inode(devnum, inum)
> soft link, create an entry, one inode but stores the target file's path



Symlink impl

> refer to `create`, allocate a inode, then write `target's len` and `target` to its data



open impl

> when get a inode, justify its type, if type is `T_SYMLINK` and `O_NOFOLLOW` not set
> then read the `target` path and recursively open for at most 10 times
> if target inode is not type `T_SYMLINK`, then found;
> otherwise, return error code





## lab mmap

memory-mapped file

https://docs.microsoft.com/en-us/dotnet/standard/io/memory-mapped-files

https://zh.wikipedia.org/wiki/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84%E6%96%87%E4%BB%B6

https://bygeek.cn/2018/05/24/understand-memory-mapped-file/

> pros
>
> user programè¯»å–å¸¸è§„æ–‡ä»¶ï¼Œè¿‡ç¨‹æ˜¯ï¼šos è¯»å–æ–‡ä»¶åˆ°kernel space bufï¼ˆç¡¬ç›˜->å†…å­˜ï¼‰ï¼Œç„¶åæ‹·è´kernel space bufåˆ°user spaceï¼ˆå†…å­˜->å†…å­˜ï¼‰
>
> é€šè¿‡mmapï¼Œè¯»å–æ–‡ä»¶ï¼Œè¿‡ç¨‹ï¼šosè¯»å–æ•°æ®æ–‡ä»¶åˆ°å†…å­˜ï¼Œä»…ä¸€æ¬¡ï¼ŒåŠ è½½ä¹‹åï¼Œuser programå¯ä»¥ç›´æ¥å¯¹ kernel space å†…å­˜è¿›è¡Œè®¿é—®
>
> mmfileè¿‡ç¨‹
> å…ˆåˆ›å»ºmmfileï¼Œå¹¶ä¸load dataåˆ°memoryä¸­
> åªæœ‰å½“user program try to access memory  in mmfile, è§¦å‘trapï¼Œæ‰ä¼šload dataåˆ°memory
>
> ä½†æ˜¯éƒ½æ˜¯éœ€è¦æœ‰va->paè¿™ä¸ªè¿‡ç¨‹ï¼Œå‡å°‘çš„åªæ˜¯copyinå’Œcopyout
>
> ç”¨æˆ·ç¨‹åºè®¿é—®çš„éƒ½æ˜¯va

```
vma_map
	ä½¿ç”¨åœºæ™¯ï¼šè¿›ç¨‹è¦è®¿é—®æŸä¸ªå¤§æ–‡ä»¶ï¼Œæƒ³åŠ é€Ÿè®¿é—®
	æµç¨‹ï¼š
		æ‰“å¼€æ–‡ä»¶è·å–fd
		mmapæ˜ å°„åˆ°va
    å†…æ ¸ä¸‹ï¼š
    é€é¡µåˆ†é…VMA
    è¿”å›(å…³é”®æ˜¯é€šè¿‡trapæ¥å®ç°lazy allocate)

trap
	åœºæ™¯ï¼šç”¨æˆ·è¿›ç¨‹è§¦å‘page faultï¼Œvaå¯¹åº”çš„paä¸å­˜åœ¨
	æµç¨‹ï¼š
		è§¦å‘page faultä¹‹å
		åˆ†é…å†…å­˜pa
		è¯»å–æ–‡ä»¶çš„æŒ‡å®šå†…å®¹åˆ°pa
		å®‰è£…vaåˆ°paçš„æ˜ å°„ï¼Œåˆ°è¿›ç¨‹çš„pgtblä¸­

vma_unmap
	ä½¿ç”¨åœºæ™¯ï¼šå…³é—­æŸä¸ªmmapå¯¹åº”çš„va
	æµç¨‹ï¼š
		éå†å½“å‰æ‰€æœ‰çš„VMA(æŒ‡å®špidå’Œva)
		é€šè¿‡å½“å‰è¿›ç¨‹çš„pgtblï¼Œä»vaåˆ°pa
		æ£€æŸ¥VMAå¯¹åº”çš„æƒé™:
			case 1 æ‹¥æœ‰è¯»å†™æƒé™
				å¦‚æœå¯¹åº”paå·²ç»åˆ†é…ï¼Œåˆ™æ£€æŸ¥å¯¹åº”PTEæ˜¯å¦dirty(è„åˆ™å†™æ–‡ä»¶)ï¼Œé‡Šæ”¾paå¯¹åº”çš„PTE
				æ²¡æœ‰åˆ†é…ï¼Œåˆ™ç›´æ¥è·³è¿‡ï¼Œé‡Šæ”¾VMA
			case 2 æ‹¥æœ‰åªè¯»æƒé™
				å¦‚æœå¯¹åº”paå·²ç»åˆ†é…ï¼Œé‡Šæ”¾æ‰paå¯¹åº”çš„PTEå³å¯
				æ²¡æœ‰åˆ†é…ï¼Œåˆ™ç›´æ¥è·³è¿‡ï¼Œé‡Šæ”¾VMA
	
```





pesist

> Persisted mmfile, when close, write it back to disk
> Non-persisted mmfile, used for IPC



### mmap

Features:

just like lazy alloc

> - Trap caused by PTE not exist -> alloc PTE, map into VMAs -> return
> - Mmap -> alloca a number of VMAs, set info
> - Munmap -> free series of VMAs, and if it's dirty, write through back to disk
> - if mmap flags is `MAP_PRIVATET`, no need to check permission. when `munmap` is called, just free all its mapped memory.
> - if mmap flags is `MAP_SHARED`, and its dirty, thus writing back is needed.



## lab networking



### net

```
The e1000_init() function we provide you in e1000.c configures the E1000 to read packets to be transmitted from RAM, and to write received packets to RAM. This technique is called DMA, for direct memory access, referring to the fact that the E1000 hardware directly writes and reads packets to/from RAM.

When the network stack in net.c needs to send a packet, it calls e1000_transmit() with an mbuf that holds the packet to be sent. Your transmit code must place a pointer to the packet data in a descriptor in the TX (transmit) ring. struct tx_desc describes the descriptor format. You will need to ensure that each mbuf is eventually freed, but only after the E1000 has finished transmitting the packet (the E1000 sets the E1000_TXD_STAT_DD bit in the descriptor to indicate this).

When the E1000 receives each packet from the ethernet, it first DMAs the packet to the mbuf pointed to by the next RX (receive) ring descriptor, and then generates an interrupt. Your e1000_recv() code must scan the RX ring and deliver each new packet's mbuf to the network stack (in net.c) by calling net_rx(). You will then need to allocate a new mbuf and place it into the descriptor, so that when the E1000 reaches that point in the RX ring again it finds a fresh buffer into which to DMA a new packet.

In addition to reading and writing the descriptor rings in RAM, your driver will need to interact with the E1000 through its memory-mapped control registers, to detect when received packets are available and to inform the E1000 that the driver has filled in some TX descriptors with packets to send. The global variable regs holds a pointer to the E1000's first control register; your driver can get at the other registers by indexing regs as an array. You'll need to use indices E1000_RDT and E1000_TDT in particular.

To test your driver, run make server in one window, and in another window run make qemu and then run nettests in xv6. The first test in nettests tries to send a UDP packet to the host operating system, addressed to the program that make server runs. If you haven't completed the lab, the E1000 driver won't actually send the packet, and nothing much will happen.

After you've completed the lab, the E1000 driver will send the packet, qemu will deliver it to your host computer, make server will see it, it will send a response packet, and the E1000 driver and then nettests will see the response packet. Before the host sends the reply, however, it sends an "ARP" request packet to xv6 to find out its 48-bit Ethernet address, and expects xv6 to respond with an ARP reply. kernel/net.c will take care of this once you have finished your work on the E1000 driver. If all goes well, nettests will print testing ping: OK, and make server will print a message from xv6!.


```



![lab-net](./images/lab-net.png)



ä¸ºä»€ä¹ˆmultiprocess pingä¼šå‡ºç°é—®é¢˜ï¼Ÿ
éå¾—æŠŠintrçš„handleræ”¹æˆwhileæ‰èƒ½æ­£ç¡®è§£å†³ï¼Ÿ

> å¦‚æœå»æ‰handlerçš„whileå¾ªç¯
> é‚£ä¹ˆä»…ä»…2ä¸ªprocess ä¸€èµ·pingï¼Œå°±å‡ºç°äº†é—®é¢˜
> https://blog.mky.moe/mit6828/10-lab10/



å¦‚ä½•æŠŠpkgåˆ†é…ç»™æŒ‡å®šçš„processï¼Ÿ

> é€šè¿‡net stackä¸æ–­å‰¥ç¦»pkgï¼Œæœ€ç»ˆudp_rxä¼šè°ƒç”¨ä¸‹é¢çš„å‡½æ•°ï¼Œä¼ é€’sport dportä»¥åŠip_addr
> ç„¶åæ£€æŸ¥æ‰€æœ‰çš„socketï¼Œé€ä¸€è¿›è¡ŒåŒ¹é…ï¼Œå¦‚æœæ‰¾åˆ°å¯¹åº”çš„socketå°±å”¤é†’ï¼›æ²¡æœ‰æ‰¾åˆ°å°±é‡Šæ”¾å¯¹åº”çš„pkg mem

```c

// called by protocol handler layer to deliver UDP packets
void
sockrecvudp(struct mbuf *m, uint32 raddr, uint16 lport, uint16 rport)
{
  //
  // Find the socket that handles this mbuf and deliver it, waking
  // any sleeping reader. Free the mbuf if there are no sockets
  // registered to handle it.
  //
  struct sock *si;

  acquire(&lock);
  si = sockets;
  while (si) {
    if (si->raddr == raddr && si->lport == lport && si->rport == rport)
      goto found;
    si = si->next;
  }
  release(&lock);
  mbuffree(m);
  return;

found:
  acquire(&si->lock);
  mbufq_pushtail(&si->rxq, m);
  wakeup(&si->rxq);
  release(&si->lock);
  release(&lock);
}
```





## lecture 15 crash recovery



todo



## lecture 16 fs performance



todo



## lecture 17 vm for application



ref https://pdos.csail.mit.edu/6.S081/2020/lec/l-uservm.txt



todo 



## lecture 18 os organization

linux, unix, xv6 -> monolithic kernel

> just one single big program, with supervisor mode.
> different modules in such a monolithic kernel, can access each other's data structure easily.

- big abstraction
- Portability
- hide complexity 
- resource management



why not monolithic?

> Cons: 
> because monolithic kernel is big and complex
> bugs -> security
> general purpose may lead to slow



Micro kernels

> tiny kernels, less code to optimize, mainly support IPC
>
> User process: like vi, compiler, window sys, fs, disk, net stack, virtual memory, paging process. 
>
> User program, using IPC throught tiny kernel to interact with each other to perform one operation.
>
> 
>
> Pros:
> dont need to pay for lots of features you're not using.
>
> 
>
> challenges:
> what's the mininum syscall API in tiny kernel?è™½ç„¶kernelå¯ä»¥å¾ˆç®€å•ï¼Œä½†æ˜¯éœ€è¦ç”¨kernelæ”¯æŒå¤æ‚çš„user program ä½†æ˜¯kernelåŠŸèƒ½å¤ªå•ä¸€äº†
>
> IPC speed?å¯¹äºmicro kernelè€Œè¨€ï¼ŒIPC speedæ˜¯ä¸€ä¸ªé‡è¦çš„è¯„ä»·æŒ‡æ ‡
>
> where to get the rest of os? like network-stack, fs



IPC speed for micro kernel

> bad design:
>
> ä¸¤ä¸ªuser processï¼ŒAå‘é€ç»™Bï¼Œç„¶åAç­‰å¾…Bçš„å›å¤ï¼ˆA send, A recv, B recv, B send)
> éœ€è¦ä¸¤ä¸ªkernel bufferè¿›è¡Œå¼‚æ­¥æ“ä½œï¼Œæ¯ä¸ªè¿›ç¨‹recvè¿‡ç¨‹ä¼šè¢«yieldä¸‹å° -> slow IPC
>
> 
>
> L4 faster IPC
>
> synchronous
>
> - un-buffered( kernel ç›´æ¥å°†msgä» user process Aæ‹·è´åˆ° user process Bä¸­ï¼Œä¸å†éœ€è¦kernel buffer) -> zero-copy
> - Small msgï¼Œå¯ä»¥ä¸ç”¨è¿›è¡Œmemory copyï¼Œç›´æ¥é€šè¿‡registeræ¥è¿›è¡ŒIPC
> - huge msg,  page mapping, much faster than memory copy
> - RPC(syscall, `call()` - `send + recv`)ï¼Œå°†ä¸¤ä¸ªsyscallåˆå¹¶ï¼Œå‡å°‘äº†ä¸€åŠçš„user <-> kernelçŠ¶æ€åˆ‡æ¢



where to get the rest of os? 

> like network-stack, fs
>
> å¦‚æœæƒ³è¦æŠŠlinux kernelé‡å†™æˆ micro kernelï¼Œå·¥ä½œé‡å·¨å¤§
>
> -> é€€è€Œæ±‚å…¶æ¬¡ï¼Œåœ¨l4 kernelä¸Šè¿è¡Œmonolithic kernel
>
> -> ç›´æ¥å¤ç”¨å¤§éƒ¨åˆ†çš„linuxï¼Œlinux kernelä½œä¸ºä¸€ä¸ªtaskï¼Œåœ¨l4ä¸Šè¿è¡Œã€‚ä½†æ˜¯æ¯ä¸ªlinux processï¼Œä½œä¸ºå•ç‹¬çš„taskåœ¨l4ä¸Šè¿è¡Œï¼Œè€Œä¸æ˜¯åœ¨linuxä¸Šè¿è¡Œ



l4 paper

> not tell us where micro kernels have enough performance to be worth using





## lecture 19 virtual machines

### trap emulate virtualization

an overview of how you could build your own virtual machine scheme



pass



## lecture 20 kernels and high-level-languages

notes https://pdos.csail.mit.edu/6.S081/2020/lec/l-biscuit.txt

movativation

> C memory safety bugs



conclusion

> HLL work pretty good
> C is faster 



## lecture 21 networking

Figure 6-1 forwaring performance of unmodified kernel

æ‹ç‚¹çš„å­˜åœ¨æ˜¯ç”±äºæ¥æ”¶packetä¹‹åéœ€è¦è€—è´¹cpuæ—¶é—´ï¼Œæ¯”å¦‚checksum æ ¡éªŒå’Œç­‰ç­‰ï¼Œå›¾è¡¨ä¸­çš„output package rateé¡¶å³°æ˜¯5000/s->å¹³å‡æ¯ä¸ªPacketè€—è´¹200å¾®ç§’

ç“¶é¢ˆçš„å­˜åœ¨æ˜¯cpuå¯¼è‡´çš„

è€Œä¸æ˜¯ç½‘ç»œå¯¼è‡´çš„ï¼Œlow level deviceè®¾å¤‡å‘é€é€Ÿåº¦åœ¨15000packages/sï¼Œä¹Ÿå°±æ˜¯å¯¹äºcomputerçš„input package ratesï¼Œæ‰€ä»¥è¯´ä¸æ˜¯ç½‘ç»œæ€§èƒ½é€ æˆçš„ï¼Œè€Œæ˜¯cpuæ€§èƒ½é€ æˆçš„



ä¸ºä»€ä¹ˆæ‹ç‚¹ä¹‹ågo downï¼Ÿè€Œä¸æ˜¯æŒå¹³ï¼Ÿ

> packageåˆ°è¾¾çš„æ—¶å€™äº§ç”Ÿintrï¼Œä»£ä»·é«˜
> intrçš„å¤„ç†ï¼Œéœ€è¦æŠŠæ•°æ®åŒ…ä»nicæ‹·è´åˆ°main memoryï¼Œè€—æ—¶é«˜
> æ‰€ä»¥è¯´ï¼Œå½“packges input rateæŒç»­èµ°é«˜ï¼Œä¼šäº§ç”Ÿå¾ˆé¢‘ç¹çš„intrï¼Œè€—è´¹å¾ˆå¤šcpuæ—¶é—´æ¥å¤„ç†





1:21:32

paper ç»™å‡ºçš„solution

åœ¨paperçš„è®¾è®¡ä¸­ï¼ŒNICä»æ¥æ²¡æœ‰è¿›è¡ŒDMAï¼Œä»æ¥æ²¡æœ‰ç›´æ¥æ¥è§¦main memoryï¼Œè‡ªå·±çš„bufferéƒ½æ˜¯é€šè¿‡NET threadæ¥è¯»å–çš„

ä¹‹æ‰€ä»¥å¯ä»¥åœ¨åˆ°è¾¾cpuæ€§èƒ½ç“¶é¢ˆä¹‹åoutput package rateä¿æŒä¸å˜ï¼Œè€Œä¸æ˜¯ä¸‹é™
æ˜¯å› ä¸ºåœ¨NICçš„æ—¶å€™ï¼Œç”±äºNICçš„buffer sizeæœ‰é™ï¼Œè¶…å‡ºçš„packageä¼šè¢«NIC dropï¼Œä»è€Œä¸ä¼šäº§ç”Ÿè¿‡å¤šçš„intrï¼Œæ¶ˆè€—cpuæ—¶é—´

ä»è€Œé¿å…äº†intr livelockï¼ˆä½†æ˜¯å¯èƒ½ä¼šæœ‰network processing live lockæˆ–è€…å…¶ä»–çš„ï¼Œåœ¨å¤šé˜¶æ®µçš„å¤„ç†è¿‡ç¨‹ä¸­ï¼Œä»»ä½•ä¸€ä¸ªèŠ‚ç‚¹éƒ½å¯èƒ½é€ æˆlive lockï¼‰

paperä¸­å¯¹äºå…¶ä»–ç±»å‹çš„live lockçš„design
NET threadä¼šå…³æ³¨ä½¿ç”¨æœ¬åœ°socketçš„åº”ç”¨ç¨‹åºï¼Œå¦‚æœå¯¹åº”çš„socket bufferæŒç»­å¢åŠ ï¼Œä»£è¡¨å¯¹åº”çš„æ•°æ®process è¿‡æ…¢ï¼Œå¦‚æœç»§ç»­å‘å¯¹åº”socket bufferä¸­æ·»åŠ æ•°æ®ï¼Œå°±ä¼šå¯¼è‡´é—®é¢˜ã€‚æ‰€ä»¥å½“socket bufferå˜é•¿çš„æ—¶å€™ï¼ŒNET threadå°±ä¼šå…³é—­å¯¹åº”çš„ç½‘å¡çš„intrï¼Œå¹¶åœæ­¢ä»ç½‘å¡ä¸­æ‹‰å‡ºæ•°æ®åŒ…åˆ°main memï¼Œç›´åˆ°socket bufferé˜Ÿåˆ—å˜çŸ­ã€‚æ„å‘³ç€ç½‘ç»œçº¿ç¨‹å°†åœæ­¢è¿è¡Œï¼Œç»™åº”ç”¨ç¨‹åºä¸€ä¸ªè¿è¡Œå’Œå¤„ç†æ•°æ®åŒ…çš„æœºä¼šã€‚



details



NICç½‘å¡å†…éƒ¨æœ‰Bufferï¼Œç”¨æ¥æ¥æ”¶æ•°æ®åŒ…
æ— è®ºæ˜¯å¦ç¦æ­¢intrï¼Œå½“packetåˆ°è¾¾çš„æ—¶å€™ï¼ŒNICæ€»ä¼šæŠŠæ•°æ®åŒ…æ·»åŠ åˆ°è‡ªå·±çš„bufferé˜Ÿåˆ—ä¸­



INTR handler routine

```
disable intr
wake up NET thread
```



NET thread

```
pull a few (fixed 5) packages from NIC
process packages
if none packages
	enable intr
	sleep
```





## lecture 22 meltdown

the kernel is mapped into every user processes address space ( but with `PTE_U` bit clear)

so if it tries to use a kernel virtual address, will get a fault



ä¸ºä»€ä¹ˆæ¯ä¸ªprocessçš„pgtbléƒ½è¦æœ‰kernel virtual addressï¼Ÿ

> Make syscalls faster, because that meant on a syscall happened, you don't have to switch page tables( which takes time and causes CPU caches to be flushed)



this is so-called `kernel address space layout randomization`

> modern kernel load the kernel at a random address, in order to make it harder to guess kernel virtual address



some time this attack works

> because of some CPU impl details
>
> one is impl trick of CPU, is called speculative execution
> two is impl trick relies on the way CPU's do caching



branch prediction and speculative exection

> è¿™ç§special attackä»…ä»…é’ˆå¯¹Intelçš„éƒ¨åˆ†CPU
>
> æ­£å¸¸æƒ…å†µä¸‹ï¼Œload variable `valid` from memoryéœ€è¦ä¸Šç™¾ä¸ªCPU cycles
> é€šè¿‡speculative exectionï¼Œç›´æ¥æ‰§è¡Œif branch æˆ–è€…else branch
> å‡è®¾å½“å‰é€‰æ‹©äº†if branchè¿›è¡Œæ‰§è¡Œï¼Œåç»­å¦‚æœç»“æœæˆç«‹ï¼Œé‚£ä¹ˆå°±ç»§ç»­æ‰§è¡Œï¼›å¦‚æœç»“æœä¸æˆç«‹ï¼Œé‚£ä¹ˆå°±cancal execution and restore the state of machine.
>
> å‡è®¾è¿™é‡Œçš„`$r0`è®¿é—®kernel va
>
> ç”±äºIntelèŠ¯ç‰‡åœ¨speculative executionçš„æ—¶å€™ï¼Œä¸ä¼šè¿›è¡Œpermission checkï¼Œè€Œæ˜¯ä¼šåœ¨ç»“æœloadå‡ºæ¥åï¼Œå†è¿›è¡Œcheckã€‚è¿™ä¸ªæ—¶å€™ï¼Œåœ¨`load variable valid`å–å›memoryä¹‹å‰ï¼Œå°±å¯ä»¥è®¿é—®kernel vaï¼Œä»è€Œattack kernel



caches

> inside CPU, there is a table stores copied PTEs from pgtbl
>
> L1 cache: 64KB, each entry is 64B, size of array is 1024.
> each entry is { va | data(pa) | perms }, access L1 cache costs few cycles
>
> L2 cache, much more biger, access costs dozen cycles
>
> when PTE changes, L1 cache need flush( today's paper, no need to flush L1 cache because we never change pgtbl)
>
> RAM costs hundreds of cycles
>
> 
>
> core1 [L1] -> [L2] -> ---------
>
> â€‹                                  |   L3  |
>
> core2 [L1] -> [L2] -> ---------







## lecture 23 RCU

Notes https://pdos.csail.mit.edu/6.S081/2020/lec/l-rcu.txt

https://zhuanlan.zhihu.com/p/30583695



Multi-core machine
how to share resources? like CPU-cache, main memory, inode cache, pgtbl?

### r/w lock

> want two readers to read parallel
>
> ```c
> //
> // A simplified version of Linux's read/write lock.
> 
> // n=0  -> not locked
> // n=-1 -> locked by one writer
> // n>0  -> locked by n readers
> struct rwlock { 
>   int n; 
> };
> 
> r_lock(l):
>   while 1:
>     x = l->n
>     if x < 0
>       continue
>     if CAS(&l->n, x, x + 1)
>       return
> 
> // CAS(p, a, b) is atomic compare-and-swap instruction
> //   if *p == a, set *p = b, return true
> //   else return false
> w_lock(l):
>   while 1:
>     if CAS(&l->n, 0, -1)
>       return
> ```
>
> 
>
> å…³é”®æ˜¯CAS atomic instruction
>
> è¿™ç§æ¯”è¾ƒç®€å•çš„r/w lockï¼Œè‡´å‘½çš„ç¼ºç‚¹ï¼š
> 1 Nä¸ªreaderï¼Œno writerï¼ŒN coreï¼šå½“xå­˜å‚¨åœ¨æ‰€æœ‰coreçš„cacheçš„æƒ…å†µä¸‹ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœæ‰€æœ‰çš„readerè¦readæˆåŠŸï¼Œéœ€è¦æ‰§è¡ŒNè½®ï¼›æ¯è½®éƒ½æ˜¯Nä¸ªCPUï¼Œè€—è´¹N^2çº§åˆ«çš„cycle
>2 å†™è¿›ç¨‹é¥¿æ­»
> 
> ```
> Surprise: r_lock() is very slow if called a lot on many cores:
>```
> 



### RCU( reader read without lock )

RCU(read-copy update) paper https://pdos.csail.mit.edu/6.S081/2020/readings/rcu-decade-later.pdf

https://blog.csdn.net/u010180372/article/details/119470638

**More details** https://pdos.csail.mit.edu/6.S081/2020/lec/l-rcu.txt

`RCU is a library for the Linux kernel that allows kernel subsystems to synchronize access to shared data in an efficient manner`

> Features
>
> - Read much faster (no longer need a lock)
> - write a bit slower (still need a lock)
>
> 
>
> ```
>   Head  ->  E1  ->  E2  ->  E3  ->  nil
>   Suppose writer wants to change the string in E2->x.
>   1. Lock
>   2. e = alloc()
>   3. e->next = E2->next
>   4. e->x = "..."
>   5. E1->next = e
>   6. Unlock
> ```
>
> challenge
>
> **RCU IDEA 1: not modify inplace; prepare a new copy**
>
> é€šè¿‡copyçš„æ–¹å¼è¿›è¡Œå…ƒç´ çš„æ›¿æ¢ï¼Œwriterå’Œreader concurrentï¼Œreaderè¦ä¹ˆçœ‹åˆ°ä¿®æ”¹å‰çš„å†…å®¹ï¼Œè¦ä¹ˆçœ‹åˆ°ä¿®æ”¹åçš„å†…å®¹ï¼Œç»å¯¹ä¸ä¼šçœ‹åˆ°half-doneçš„å†…å®¹
>
> ```
> A good way to think about this idea:
>   Update of E1->next is a "committing write".
>   Before, it's as if nothing changed.
>   After, all changes are made visible.
> ```
>
> 
>
> problem fixed: 
>
> ```
> If there is a concurrent writer?
>     1. Modifying the string in a list element?
> ```
>
> 
>
> **RCU IDEA 2: readers and writers must use memory barriers to enforce order**
>
> prevent cc reorder instruction
>
> ```
>   Writer must have a barrier just before step 5.
>   Reader needs a barrier between Rx = E1->next,
>     and dereference of Rx to read element contents.
> ```
>
> problem fixed:
>
> ```
> If there is a concurrent writer?
>     2. Inserting a new list element?
> ```
>
> 
>
> **RCU IDEA 3: defered freeze**
>
> ```
>   The problem: a reader might be looking at the element to be deleted.
>   Writer needs to give readers time to finish.
>     After it removes the visible reference to the element.
>     But how long should the writer wait?
>   Could use GC or reference counts, but they are expensive.
> ```
>
> 
>
> Key points
>
> ```
>   1. Reader isn't allowed to hold pointer to RCU data across context switch.
>      Similar to rule that spin-lock can't be held across context switch.
>   2. Writer defers free until all CPUs have context-switched.
>   How to do this?
>     Simple plan: writer forces itself to be scheduled on each CPU.
>     (There are more efficient implementations.)
> ```
>
> problem fixed:
>
> ```
>   If there is a concurrent writer?
>     3. Deleting an element?
> ```
>
> when to free an unused old element?( å‡è®¾æœ‰readerè¿˜åœ¨è¯»å–è¿™ä¸ªelement )
>
> method 1, use refcnt, wait refcnt equals zero (bad, because RCU æœ¬èº«ä¸ä¼šæ¶‰åŠè¿‡å¤šçš„å†™å…¥æ“ä½œ)
>
> method 2, GC maybe
>
> method 3, RCU rules.
> this technique doesn't prevent from free, it prevents us from freeing some node still using
>
> 
>
> simple use of RCU
>
> ```pseudocode
> // list reader:
> rcu_read_lock() // -------------------- rcu critical section
> // no context switch
> e = head
> while(p){
> 	e = rcu_dereference(e) // memory barrier + return pointer
> 	look at e->x ...
> 	e = e->next
> }
> rcu_read_unlock() // ------------------- rcucritical section
> 
> 
> // replace the first list element:
> acquire(lock) // ex-lock, like spinlock
> old = head
> e = alloc()
> e->x = ...
> e->next = head->next
> rcu_assign_pointer(&head, e) // barrier
> release(lock)
> 
> synchronize_rcu()
> free(old)
> ```
>
> 



## lecture 24 final Q&A







# æ•´ä½“å°è±¡





## kalloc.c

åˆå§‹åŒ–kernelå†…å­˜ï¼Œæä¾›é“¾è¡¨ä»¥ç”³è¯·ã€é‡Šæ”¾å†…å­˜

> PHYSTOPèŒƒå›´å†…éƒ¨çš„å†…å­˜ï¼Œmemsetä¹‹åï¼Œé€é¡µæ·»åŠ åˆ°freelistä¸­ï¼›éœ€è¦kernelç”³è¯·å†…å­˜æ—¶ï¼Œç”³è¯·å³å¯ï¼Œè°ƒç”¨kallocï¼Œä»é“¾è¡¨ä¸­å–å‡º





## vm.c

kvm

kvmmake

> åˆ›å»ºkernelçš„pgtblï¼Œinstall è‹¥å¹²va==paï¼Œszï¼Œpermï¼ˆå¸¸é‡åœ°å€ï¼ŒPTE_R PTE_W PTE_Xç­‰ç­‰è¯»å†™æ‰§è¡Œæƒé™ï¼‰ï¼Œä»¥åŠKernel stack



kernel stackçš„ç”±æ¥

> vm.cä¸­çš„kvmmakeï¼Œæœ€åä¼šè°ƒç”¨`proc.c`ä¸‹çš„`proc_mapstacks`
> `proc_mapstacks`è¿™ä¸ªå‡½æ•°ï¼Œæš´åŠ›éå†æ‰€æœ‰procç»“æ„ï¼Œä¸ºæ¯ä¸ªprocéƒ½ç”³è¯·ä¸€é¡µpageï¼Œå¹¶å®‰è£…va: TRAMPOLINE-2\*PAGE åˆ° ç”³è¯·çš„paï¼Œå³å¯ä¿è¯æ‰€æœ‰è¿›ç¨‹éƒ½ä¼škernel stack





mappages

> å®‰è£…va->paçš„æ˜ å°„åˆ°pgtblä¸­ ï¼ˆinstallåˆ°pgtblçš„paï¼Œä¸€å®šæ˜¯å·²ç»ä»kalloc.cä¸­ç”³è¯·åˆ°çš„å†…å­˜ï¼‰



uvmunmap

> åœ¨pgtbl uninstall vaåˆ°paçš„æ˜ å°„ï¼Œè®¾ç½®å¯¹åº”çš„PTE_Véæ³•ï¼Œï¼ˆå¦‚æœéœ€è¦freeåˆ™é‡Šæ”¾å†…å­˜ï¼Œå½’è¿˜åˆ°é“¾è¡¨ä¸­ï¼‰



copyin

> æ‹·è´ç”¨æˆ·å†…å­˜åˆ°kernelå†…å­˜ä¸­ï¼ˆå®é™…ä¸Šä»…ä»…æ˜¯ä¸ªç®€å•çš„å†…å­˜æ‹·è´ï¼Œè¿™é‡Œè¯´çš„"å†…å­˜"éƒ½æŒ‡çš„æ˜¯paï¼Œå¯¹äºç”¨æˆ·å†…å­˜vaè€Œè¨€ï¼Œéœ€è¦æŸ¥pgtblè·å–å¯¹åº”çš„paï¼‰
> ç„¶åmemmove



copyout

> æ‹·è´kernelå†…å­˜åˆ°ç”¨æˆ·å†…å­˜





æ ¹æ®pgtblï¼Œè¾“å…¥vaï¼Œè¿”å›å¯¹åº”çš„pa



## proc.c



### è¿›ç¨‹fork

forkä¸allocproc

> ```
> allocproc
> æµç¨‹ï¼š
> 	1 å¯»æ‰¾å¯ç”¨çš„proc
> 	2 è®¾ç½®pid
> 	3 åˆ†é…ä¸€é¡µpageï¼Œä¿å­˜åˆ°p->trapframe
> 	4 åˆ†é…pgtblï¼Œä¿å­˜åˆ°p->pagetable
> 	5 è®¾ç½®p->context.raä¸ºforkret(forkå‡ºæ¥çš„å­è¿›ç¨‹ä¸‹æ¬¡æ‰§è¡Œè¿™ä¸ªå‡½æ•°ï¼Œç±»ä¼¼äºåç¨‹)ï¼Œè®¾ç½®p->context.spä¸ºp->kstackæ ˆé¡¶
> ```
>
> åŒç†freepocï¼Œé‡Šæ”¾p->pagetableï¼Œé‡Šæ”¾p->trapframe
>
> 
>
> fork
>
> ```
> æµç¨‹ï¼š
> 	1 è°ƒç”¨allocproc()ï¼Œæ„é€ ä¸€ä¸ªæ–°çš„procä½œä¸ºå­è¿›ç¨‹
> 	2 æ‹·è´parent pgtblåˆ°child pgtbl
> 	3 ä¿å­˜user registers(p->trapframe)
> 	4 æ‹·è´file*æ•°ç»„
> 	5 è®¾ç½®childçš„parentï¼Œä»¥åŠstate
> 	6 çˆ¶å­è¿›ç¨‹å„è‡ªè¿”å›ï¼Œçˆ¶è¿›ç¨‹è¿”å›åŸç¨‹åºï¼Œå­è¿›ç¨‹è°ƒç”¨forkret
> 	
> ```
>
> 
>
> forkretï¼Œæœ€ä¸»è¦è¿˜æ˜¯è°ƒç”¨usertrapret
>
> 



### è¿›ç¨‹è°ƒåº¦

yield sched swtch.S scheduler

> æ€»æµç¨‹ï¼š
> yield: å½“å‰è¿›ç¨‹æ”¾å¼ƒCPUï¼Œè°ƒç”¨sched ->
> sched: æ‰§è¡Œswtch.Sï¼Œæ¢å¤å½“å‰CPUå¯¹åº”çš„schedulerè¿›ç¨‹->
> scheduler: ç»§ç»­ä¸Šæ¬¡çš„å¾ªç¯ï¼Œé€‰è¿›ç¨‹ï¼Œæ‰§è¡Œ->å¦‚æ­¤å¾ªç¯
>
> yieldï¼Œæ”¾å¼ƒå½“å‰è¿›ç¨‹ï¼Œé€‰æ‹©å…¶ä»–è¿›ç¨‹ä¸Šå°
>
> ```
> æµç¨‹ï¼š
> 	1 è®¾ç½®å½“å‰è¿›ç¨‹çš„state
> 	2 è°ƒç”¨sched
> ```
>
> 
>
> sched
>
> ```
> æµç¨‹ï¼š
> 	1 è°ƒç”¨swtch.Sï¼Œå°†å½“å‰CPUçš„çŠ¶æ€å­˜å‚¨åˆ°p->contextä¸­ï¼Œä»mycpu()->contextæ¢å¤åˆ°CPUçŠ¶æ€
> ```
>
> 
>
> swtch.S
>
> ```
> æµç¨‹ï¼š
> 	1 ä¿å­˜å½“å‰CPUå¯„å­˜å™¨ï¼Œè¦†ç›–åˆ°p->contextä¸­
> 	2 ä»mycpu()->contextä¸­è¯»å–å¯„å­˜å™¨ï¼Œæ¢å¤åˆ°CPUå¯„å­˜å™¨ä¸­(è¿™é‡Œçš„æ¢å¤ï¼Œå¯¹åº”schedulerçš„ç¬¬ä¸‰é˜¶æ®µï¼Œä¹Ÿå°±æ˜¯è½¬ç§»åˆ°scheduler)
> ```
>
> 
>
> mycpu->contextä»£è¡¨çš„ä¸æ˜¯è¿™ä¸ªCPU()å¯¹åº”çš„ä¸Šä¸‹æ–‡ï¼Œè€Œæ˜¯kernel threadçš„scheduler
>
> 
>
> schedulerï¼Œæ‰§è¡Œå®é™…çš„è¿›ç¨‹è°ƒåº¦
> **Per-CPU process schedulerï¼Œæ¯ä¸ªCPUå„è‡ªä¸€ä¸ªschedulerï¼Œç”¨æ¥ä¿å­˜schedulerçš„æ‰§è¡Œæƒ…å†µ**
>
> ```
> æµç¨‹ï¼š
> 	æ­»å¾ªç¯ï¼Œä¸‰é˜¶æ®µ
> 	- choose a process to run
> 	- swtch to run that process
> 	- eventually process transfers control, swtch back to scheduler
> ```
>
> 



### waitä¸ TODO exit

> wait
> æ‰«æprocï¼Œç­‰å¾…ä¸€ä¸ªå­è¿›ç¨‹å¤„äºZOMBIEï¼Œå›æ”¶è¯¥å­è¿›ç¨‹çš„procç»“æ„
>
> ```
> æµç¨‹ï¼š
> 	æ¯æ¬¡æ‰«æä¸€è½®ä¸æ–­æ‰«ææ‰€æœ‰proc
> 		æ‰¾åˆ°ä¸€ä¸ªchildï¼Œä¸”childå¤„äºZOMBIEï¼Œåˆ™é‡Šæ”¾childçš„procç»“æ„ï¼Œå¹¶è¿”å›pid
> 		å¦‚æœæ²¡æœ‰childï¼Œåˆ™è¿”å›-1
> 		å¦åˆ™ï¼Œsleep
> ```
>
> 
>
> exit
>
> ```
> ```
>
> 



memlayout



kerneltrap



sche

sched

schedule





## trampoline.Så’Œtrap.c



trampoline

> æ±‡ç¼–å‡½æ•°
>
> åœºæ™¯ï¼šswitch from user to kernelï¼Œä¹Ÿå°±æ˜¯user programæ‰§è¡Œç³»ç»Ÿè°ƒç”¨
> åŸç†ï¼šå½“å‰CPUå¯„å­˜å™¨ä»£è¡¨è¿™ä¸ªè¿›ç¨‹çš„æ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œé€šè¿‡æ±‡ç¼–ä¿å­˜åˆ°å†…æ ¸ç©ºé—´ä¸‹å¯¹åº”è¿›ç¨‹çš„proc->trapframeä¸­
> å…·ä½“ï¼š
> 1 ä¿å­˜å½“å‰ç”¨æˆ·è¿›ç¨‹çš„ä¸Šä¸‹æ–‡åˆ°p->trapframe
> 2 åŠ è½½kernelçš„ä¸Šä¸‹æ–‡ï¼Œp->trapframe->{kernel_sp, kernel_satpç­‰ç­‰}ï¼Œå®ŒæˆçŠ¶æ€åˆ‡æ¢
> 3 è°ƒç”¨usertrapï¼Œæ‰§è¡Œç³»ç»Ÿè°ƒç”¨



trampoline: { çŠ¶æ€åˆ‡æ¢åˆ°kernelï¼Œç„¶åè°ƒç”¨ usertrap } ->
usertrap: { æ‰§è¡Œsyscallï¼Œç„¶åè°ƒç”¨ usertrapret } ->
usertrapret: { çŠ¶æ€è¿”å›ï¼Œç„¶åè°ƒç”¨ userret } ->
userret: { è¯»å–p->trapframeçš„æ•°æ®ï¼Œåˆ°å½“å‰CPUå¯„å­˜å™¨ï¼Œæ¢å¤ä¸Šä¸‹æ–‡ }

usertrap

> èƒŒæ™¯ï¼šåœ¨å½“å‰è¿›ç¨‹å·²ç»å®ŒæˆçŠ¶æ€åˆ‡æ¢å‰æä¸‹ï¼Œæ‰§è¡Œå¯¹åº”ç³»ç»Ÿè°ƒç”¨
> å…·ä½“ï¼šæ£€æŸ¥faultåŸå› ï¼Œæ‰§è¡Œå¯¹åº”çš„syscallï¼Œç„¶åæ‰§è¡Œusertrapret



p->trapframe->{a0~a5 ä¾æ¬¡æ˜¯ç³»ç»Ÿè°ƒç”¨çš„6ä¸ªå‚æ•° }



### è™šæ‹Ÿå†…å­˜ è¿›ç¨‹ç®¡ç†

vm uvm kvm

æ•´ä¸ªosçš„å†…å­˜å¦‚ä½•ç®¡ç†

æ¯ä¸ªè¿›ç¨‹çš„å†…å­˜å¦‚ä½•ç®¡ç†



è¿›ç¨‹ç®¡ç†

è¿›ç¨‹è°ƒåº¦ è¿›ç¨‹ç»“æ„ syscallçš„å®ç°





- kinitï¼šè®¾ç½®å¥½é¡µè¡¨åˆ†é…å™¨ï¼ˆpage allocatorï¼‰
- kvminitï¼šè®¾ç½®å¥½è™šæ‹Ÿå†…å­˜ï¼Œè¿™æ˜¯ä¸‹èŠ‚è¯¾çš„å†…å®¹
- kvminithartï¼šæ‰“å¼€é¡µè¡¨ï¼Œä¹Ÿæ˜¯ä¸‹èŠ‚è¯¾çš„å†…å®¹
- processinitï¼šè®¾ç½®å¥½åˆå§‹è¿›ç¨‹æˆ–è€…è¯´è®¾ç½®å¥½è¿›ç¨‹è¡¨å•
- trapinit/trapinithartï¼šè®¾ç½®å¥½user/kernel modeè½¬æ¢ä»£ç 
- plicinit/plicinithartï¼šè®¾ç½®å¥½ä¸­æ–­æ§åˆ¶å™¨PLICï¼ˆPlatform Level Interrupt Controllerï¼‰ï¼Œæˆ‘ä»¬åé¢åœ¨ä»‹ç»ä¸­æ–­çš„æ—¶å€™ä¼šè¯¦ç»†çš„ä»‹ç»è¿™éƒ¨åˆ†ï¼Œè¿™æ˜¯æˆ‘ä»¬ç”¨æ¥ä¸ç£ç›˜å’Œconsoleäº¤äº’æ–¹å¼
- binitï¼šåˆ†é…buffer cache
- iinitï¼šåˆå§‹åŒ–inodeç¼“å­˜
- fileinitï¼šåˆå§‹åŒ–æ–‡ä»¶ç³»ç»Ÿ
- virtio_disk_initï¼šåˆå§‹åŒ–ç£ç›˜
- userinitï¼šæœ€åå½“æ‰€æœ‰çš„è®¾ç½®éƒ½å®Œæˆäº†ï¼Œæ“ä½œç³»ç»Ÿä¹Ÿè¿è¡Œèµ·æ¥äº†ï¼Œä¼šé€šè¿‡userinitè¿è¡Œç¬¬ä¸€ä¸ªè¿›ç¨‹ï¼Œè¿™é‡Œæœ‰ç‚¹æ„æ€ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬çœ‹ä¸€ä¸‹userinit
